{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Flugpreis Vorhersage - Kaufen oder Warten?\n",
    "## Projektarbeit Data Mining\n",
    "___\n",
    "### Wintersemester 2021/22\n",
    "### Gruppe G:\n",
    "Max Grundmann - s0559326\n",
    "### Inhalte\n",
    "1. Exploratory Data Analysis (EDA)\n",
    "### 2. Datenvorbereitung\n",
    "3. Modelauswahl\n",
    "4. Testing\n",
    "___\n",
    "Dieses Notebook implementiert die nötigen Schritte zur Transformation der Daten, Feature Engineering und -generierung und wendet sie auf die Trainings- und Testdaten an, um sie für das Training vorzubereiten.\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "031ce98b",
   "metadata": {},
   "source": [
    "Benötigte Bibliotheken importieren"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 492,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from numpy import asarray\n",
    "from datetime import datetime, timedelta\n",
    "import logging\n",
    "import tqdm\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0efab602",
   "metadata": {},
   "source": [
    "Dateipfade festlegen "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 493,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "logging.basicConfig(level=logging.INFO, format='%(levelname)s -  %(asctime)s: %(message)s')\n",
    "\n",
    "dirname = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 494,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_price_history(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Generiert die Preishistorie für alle Flüge in einem Dataframe und verkettet sie in einem Feld.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): Input Dataframe\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Output Dataframe mit Preishistorie.\n",
    "    \"\"\"\n",
    "    temp = df.copy()\n",
    "    temp = temp.sort_values(by='Request_Date', axis=0, ascending=True)\n",
    "    temp['Price_In_Eur'] = temp['Price_In_Eur'].astype(str)\n",
    "\n",
    "    price_history = temp.groupby(['flight_unique_id'])['Price_In_Eur'].apply(','.join).reset_index()\n",
    "    return price_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 495,
   "id": "418ec50d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_price_history(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Führt die Daten mit der generierten Preishistorie zusammen.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): Input Dataframe\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Output Dataframe mit Preishistorie\n",
    "    \"\"\"\n",
    "    prices = get_price_history(df)\n",
    "    temp = df.copy()\n",
    "    \n",
    "    split_to_columns = prices\n",
    "    split_to_columns['flight_unique_id'] = prices['flight_unique_id']\n",
    "\n",
    "    return pd.merge(left=temp, right=split_to_columns, how='left', on='flight_unique_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 496,
   "id": "768d6ed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_previous_requests(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Findet die Anzahl vorheriger Anfragen für eine gegebene FlightID\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): Input Dataframe\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Output Dataframe mit Spalte Anzahl vorheriger Anfragen\n",
    "    \"\"\"\n",
    "    temp = df.copy()\n",
    "    temp = temp.sort_values(['flight_unique_id', 'Request_Date'])\n",
    "    unique_flights = temp['flight_unique_id'].unique()\n",
    "\n",
    "    requests_counter = 0\n",
    "    flight_id_index = 0\n",
    "    current_flight = unique_flights[flight_id_index]\n",
    "    number_of_requests_per_row = []\n",
    "\n",
    "    for index, row in  temp.iterrows():\n",
    "        if row['flight_unique_id'] != current_flight:       \n",
    "            flight_id_index += 1\n",
    "            current_flight = unique_flights[flight_id_index]\n",
    "            requests_counter = 0\n",
    "        number_of_requests_per_row.append(requests_counter)\n",
    "        requests_counter += 1\n",
    "\n",
    "    temp['previous_requests'] = number_of_requests_per_row\n",
    "    return temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 497,
   "id": "8f5f6210",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_price_of_closest_flight(df: pd.DataFrame, new_name:str, fill_with_column: str, previous: bool =False) -> pd.DataFrame:\n",
    "    \"\"\"Liefert den Preis des jeweils dichtesten Fluges der selben Strecke zurück.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): Input Dataframe\n",
    "        new_name (str): Name der neuen Spalte\n",
    "        fill_with_column (str): Name der Spalte die den relevanten Wert enthält\n",
    "        previous (bool, optional): Richtung der Berechnung. Defaults to False.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Output Dataframe\n",
    "    \"\"\"\n",
    "    temp = df.copy()\n",
    "\n",
    "    temp['Flight_Date_Time'] = temp.apply(lambda x: x['Flight_Date'] + timedelta(hours=x['Departure_hour']), axis=1)\n",
    "    temp = temp.sort_values(['route_abb', 'Flight_Date_Time'], axis=0)\n",
    "\n",
    "    routen = temp['route_abb'].unique()\n",
    "    df_list = []\n",
    "\n",
    "    temp[new_name] = 0.0\n",
    "\n",
    "    for route in routen:\n",
    "        subset = temp[temp['route_abb'] == route].reset_index(drop=True)\n",
    "\n",
    "        for index, row in subset.iterrows():\n",
    "            f1 = subset[subset['flight_unique_id'] != row['flight_unique_id']] \n",
    "\n",
    "            if previous:\n",
    "                f2 = f1[f1['Flight_Date_Time'] <= row['Flight_Date_Time']]\n",
    "                f3 = f2[f2['Request_Date'] >= row['Request_Date']]\n",
    "            else:\n",
    "                f2 = f1[f1['Flight_Date_Time'] >= row['Flight_Date_Time']]\n",
    "                f3 = f2[f2['Request_Date'] >= row['Request_Date']]\n",
    "                \n",
    "            f4 = f3.sort_values(['Flight_Date_Time', 'Request_Date'])\n",
    "\n",
    "            if index >= len(f4):\n",
    "                if len(f4) == 0:\n",
    "                    subset.at[index, new_name] = 0\n",
    "                else:\n",
    "                    subset.at[index, new_name] = f4[fill_with_column].iloc[0] \n",
    "            else:    \n",
    "                subset.at[index, new_name] = f4[fill_with_column].iloc[0] \n",
    "        \n",
    "        df_list.append(subset)\n",
    "    return pd.concat(df_list).reset_index(drop=True).drop(['Flight_Date_Time'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02a3b36c",
   "metadata": {},
   "source": [
    "#### 2. Hide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 498,
   "id": "d6fc4f92",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_delta_till_next_flight(df: pd.DataFrame, forward: bool=True) -> pd.DataFrame:\n",
    "    \"\"\"Diese Funktion berechnet die Zeit bis zum nächsten Flug der selben FlightID.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): Input Dataframe\n",
    "        forward (bool, optional): Bestimmt die Richtung der Berechnung. Defaults to True.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: _description_\n",
    "    \"\"\"\n",
    "    temp = df.copy()\n",
    "    org = df.copy()\n",
    "\n",
    "    temp['Departure_Time'] = temp.apply(lambda x: x['Flight_Date'] + timedelta(hours=x['Departure_hour']), axis=1)\n",
    "    org['Flight_Date_Time'] = org.apply(lambda x: x['Flight_Date'] + timedelta(hours=x['Departure_hour']), axis=1)\n",
    "    \n",
    "    temp = temp.sort_values(by=['route_abb', 'Departure_Time'], axis=0, ascending=forward)\n",
    "    routen = temp['route_abb'].unique()\n",
    "\n",
    "    sorted_df = temp\n",
    "    df_list = []\n",
    "\n",
    "    for route in routen:\n",
    "        temp = sorted_df[sorted_df['route_abb'] == route]\n",
    "        temp = pd.DataFrame(temp[['Departure_Time', 'route_abb']])\n",
    "        temp = temp.drop_duplicates()\n",
    "        temp.rename(columns={ 'Departure_Time': 0}, inplace=True)\n",
    "\n",
    "        if forward:\n",
    "            temp['delta'] = temp[0] - temp[0].shift()\n",
    "            column_name = 'last_departure'\n",
    "        else:\n",
    "            temp['delta'] = temp[0].shift() - temp[0]\n",
    "            column_name = 'next_departure'\n",
    "\n",
    "        temp['delta'] = temp['delta'].dt.seconds / 60 / 60\n",
    "        temp['delta'] = temp['delta'].fillna(0)\n",
    "        temp.rename(columns={ 0: 'Flight_Date_Time', 'delta' :column_name,}, inplace=True)\n",
    "        \n",
    "        df_list.append(temp)\n",
    "\n",
    "    mapping = pd.concat(df_list)\n",
    "\n",
    "    mapping = mapping.dropna()\n",
    "\n",
    "    org = pd.merge(left=org, right=mapping, how='inner', on=['Flight_Date_Time', 'route_abb'])\n",
    "\n",
    "    return org.drop(columns='Flight_Date_Time', axis=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 499,
   "id": "d320bc82",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_last_n_prices(df: pd.DataFrame, n:int =10) -> pd.DataFrame:\n",
    "    \"\"\"Liefert die Preishistorie für eine gegebene Anzahl an historischen Anfragen.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): Input Dataframe\n",
    "        n (int, optional): Anzahl an historischen Preisen. Defaults to 10.\n",
    "\n",
    "    Returns:\n",
    "        (pd.DataFrame): Output Dataframe mit Preishistorie\n",
    "    \"\"\"\n",
    "    last_n_requests = n\n",
    "    Prices = []\n",
    "    temp = df.copy()\n",
    "\n",
    "    for row in temp.itertuples():\n",
    "        row_prices = []\n",
    "        for i in range(row.previous_requests):\n",
    "            if len(row_prices) >= last_n_requests:\n",
    "                row_prices.pop(0)    \n",
    "            row_prices.append(getattr(row, 'Price_In_Eur_y').split(',')[i])\n",
    "        Prices.append(','.join(row_prices))\n",
    "\n",
    "    temp['Prices_cut'] = Prices\n",
    "    split_to_columns = temp['Prices_cut'].str.split(',', expand=True)\n",
    "    split_to_columns = split_to_columns.apply(pd.to_numeric)\n",
    "    split_to_columns.columns = split_to_columns.columns.map(str)\n",
    "\n",
    "    return pd.concat([temp.drop(['Prices_cut', 'Price_In_Eur_y'], 1), split_to_columns], axis=1).rename(columns={'Price_In_Eur_x' : 'Price_In_Eur'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 500,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_data(data: pd.DataFrame, last_n_requests: int, test: bool = False) -> pd.DataFrame:\n",
    "    \"\"\"Wendet die benötigten Transformationen auf die Rohdaten an und gibt ein fertiges DataFrame für das Training zurück.\n",
    "\n",
    "    Args:\n",
    "        data (pd.DataFrame): Input Dataframe\n",
    "        last_n_requests (int): Anzahl Schritte die die Preishistorie zurückgeht\n",
    "        test (bool): Test- oder Trainingsset\n",
    "    Returns:\n",
    "        pd.DataFrame: Output Dataframe\n",
    "    \"\"\"\n",
    "    \n",
    "    logging.info('Pipeline gestartet.')\n",
    "    # Datentypen ändern\n",
    "    data['Flight_Date'] = pd.to_datetime(data['Flight_Date'])\n",
    "    data['Request_Date'] = pd.to_datetime(data['Request_Date']).dt.tz_localize(None)\n",
    "    \n",
    "    # Abstand zu letztem und nächsten Flug berechnen\n",
    "    forward = calculate_delta_till_next_flight(data, forward=True).reset_index(drop=True)\n",
    "    backward = calculate_delta_till_next_flight(forward, forward=False)\n",
    "    data = backward\n",
    "\n",
    "    # Preis des dichtesten letzten und nächsten Fluges berechnen\n",
    "    data = get_price_of_closest_flight(data, 'price_of_next_flight', 'Price_In_Eur')\n",
    "    data = get_price_of_closest_flight(data, 'price_of_previous_flight', 'Price_In_Eur', previous=True)\n",
    "\n",
    "    # One Hot Encoding für Routen-Bezeichnungen\n",
    "    data = pd.get_dummies(data,prefix=['route'], columns = ['route_abb'], drop_first=False)\n",
    "    \n",
    "    # Flag, wenn die Anfrage die letzte Anfrage vor dem Flug ist\n",
    "    is_last_request = pd.DataFrame(data.groupby('flight_unique_id')['Request_Date'].max()).reset_index()\n",
    "    is_last_request['is_last_request'] = 1\n",
    "\n",
    "    data = data.merge(is_last_request, \n",
    "                      on=['flight_unique_id', 'Request_Date'], \n",
    "                      how='left')\n",
    "    data['is_last_request'] = data['is_last_request'].fillna(0)\n",
    "    data['is_last_request'] = data['is_last_request'].astype(int)\n",
    "    \n",
    "    # Anzahl der bisherigen Requests als Feature hinzufügen\n",
    "    data = get_previous_requests(data)\n",
    "    \n",
    "    # Preishistorie berechnen\n",
    "    data = merge_price_history(data)\n",
    "    data = get_last_n_prices(data, last_n_requests)\n",
    "\n",
    "    # Preisänderung zur letzten Abfrage in %\n",
    "    print(data)\n",
    "    data['PriceChange'] = data.apply(\n",
    "        lambda row:( (row['Price_In_Eur'] / row[str(last_n_requests-1)] )-1 if (row['previous_requests'] >= last_n_requests or row['previous_requests'] == 0) else (row['Price_In_Eur'] / row[ str(row['previous_requests'] -1) ]) - 1), axis=1)\n",
    "\n",
    "    # Datumsfelder in einzelne Bestandteile zerlegen\n",
    "    data['flight_weekday'] = data['Flight_Date'].dt.weekday\n",
    "    data['flight_day'] = data['Flight_Date'].dt.day\n",
    "    data['flight_month'] = data['Flight_Date'].dt.month \n",
    "    data['flight_is_weekend'] = data['flight_weekday'] >= 5\n",
    "\n",
    "    data['request_weekday'] = data['Request_Date'].dt.weekday\n",
    "    data['request_day'] = data['Request_Date'].dt.day\n",
    "    data['request_month'] = data['Request_Date'].dt.month\n",
    "    data['request_is_weekend'] = data['request_weekday'] >= 5\n",
    "    \n",
    "    data['request_hour'] = data['Request_Date'].dt.hour\n",
    "    \n",
    "    # Cyclische Features in Sinus und Cosinus Repräsentation umwandeln\n",
    "    # Quelle: https://www.mikulskibartosz.name/time-in-machine-learning/\n",
    "    def encode(data, col, max_val):\n",
    "        data[col + '_sin'] = np.sin(2 * np.pi * data[col]/max_val)\n",
    "        data[col + '_cos'] = np.cos(2 * np.pi * data[col]/max_val)\n",
    "        return data\n",
    "\n",
    "    data = encode(data, 'request_weekday', 7)\n",
    "    data = encode(data, 'request_month', 12)\n",
    "    data = encode(data, 'request_day', 365)\n",
    "    data = encode(data, 'request_hour', 24)\n",
    "\n",
    "    data = encode(data, 'flight_weekday', 7)\n",
    "    data = encode(data, 'flight_month', 12)\n",
    "    data = encode(data, 'flight_day', 365)\n",
    "    data = encode(data, 'Departure_hour', 24)\n",
    "    \n",
    "    # Tage bis zum Flug berechnen\n",
    "    data['Request_Date_w/o_Time'] = pd.to_datetime(data['Request_Date']).dt.date\n",
    "    data['days_remaining'] = (pd.to_datetime(data['Flight_Date']).dt.date - data['Request_Date_w/o_Time']).dt.days\n",
    "    data.drop(['Request_Date_w/o_Time'],1, inplace=True)\n",
    "    \n",
    "    # Relevante Feiertage im Zeitraum der Daten, die in Berlin und oder Frankfurt gelten\n",
    "    # sowie Public Holidays in Großbritannien. \n",
    "    feiertage = {\n",
    "        '2019-06-09':'Pfingstsonntag',\n",
    "        '2019-06-10':'Pfingstmontag',\n",
    "        '2019-06-20':'Fronleichnam',\n",
    "        '2019-06-20':'Schulferien Beginn',\n",
    "        '2019-08-02':'Schulferien Ende',\n",
    "        '2019-08-26':'Summer Bank Holidays',\n",
    "        '2019-07-15':'School Summer Holidays Beginn',\n",
    "        '2019-09-06':'School Summer Holidays End'}\n",
    "\n",
    "    feiertage_df = pd.DataFrame(feiertage.items(), columns=['Datum_Feiertag', 'Feiertag_Bezeichnung'])\n",
    "    feiertage_df['Datum_Feiertag'] = pd.to_datetime(feiertage_df['Datum_Feiertag'])\n",
    "    \n",
    "    from datetime import datetime\n",
    "\n",
    "    day_diff_list = []\n",
    "    for index, row in feiertage_df.iterrows():\n",
    "        day_diff_list.append(abs((data['Flight_Date'] - row['Datum_Feiertag']).dt.days))\n",
    "        \n",
    "    feiertage_diff_df = pd.concat(day_diff_list, axis=1)\n",
    "    feiertage_diff_df = feiertage_diff_df.min(axis=1)\n",
    "    feiertage_diff_df = feiertage_diff_df.reset_index().drop('index', 1)\n",
    "    feiertage_diff_df.columns = ['Days_Untill_Event']\n",
    "\n",
    "    data = pd.concat([data, feiertage_diff_df], axis=1)\n",
    "\n",
    "    try:\n",
    "        data.drop(['index'], axis=1, inplace=True)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    # Features skalieren\n",
    "    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
    "    dont_scale = ['is_last_request']\n",
    "    if not test: \n",
    "        dont_scale.append('buy')\n",
    "        dont_scale.append('min_future_price_in_Eur')\n",
    "    to_be_scaled = data.select_dtypes(include=numerics).drop(dont_scale, axis=1)\n",
    "    data.drop(to_be_scaled.columns, axis=1, inplace=True)\n",
    "    \n",
    "    if not test:\n",
    "        scaler = MinMaxScaler()\n",
    "        scaled = pd.DataFrame(scaler.fit_transform(to_be_scaled), columns=to_be_scaled.columns)\n",
    "        joblib.dump(scaler, '../Models/Scalers/minmax.gz')\n",
    "    else:\n",
    "        scaler = joblib.load('../Models/Scalers/minmax.gz')\n",
    "        scaled = pd.DataFrame(scaler.transform(to_be_scaled), columns=to_be_scaled.columns)\n",
    "\n",
    "    data = pd.concat([data.reset_index(), scaled.reset_index()], axis=1)\n",
    "\n",
    "    # Nicht mehr benötigte Spalten entfernen\n",
    "    drop_list = ['Request_Date', \n",
    "               'Flight_Date',  \n",
    "            #    'index', \n",
    "               'Departure_hour', \n",
    "               'flight_weekday', \n",
    "               'flight_day', \n",
    "               'flight_month', \n",
    "               'request_weekday', \n",
    "               'request_day', \n",
    "               'request_month', \n",
    "            #    'days_remaining',\n",
    "               'request_hour', \n",
    "            #    'Days_Untill_Event',\n",
    "            #    'previous_requests',\n",
    "               'flight_unique_id']\n",
    "    if not test: drop_list.append('min_future_price_in_Eur')\n",
    "    data.drop(drop_list, inplace=True, axis=1)\n",
    "    \n",
    "    # Boolean in Int umwandeln\n",
    "    data['request_is_weekend'] = data['request_is_weekend'].astype(int)\n",
    "    data['flight_is_weekend'] = data['flight_is_weekend'].astype(int)\n",
    "    \n",
    "    try:\n",
    "        data.drop(['index'], axis=1, inplace=True)\n",
    "        data.drop(['index'], axis=1, inplace=True)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    logging.info('Pipeline beendet.')\n",
    "    return data.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3024cd6b",
   "metadata": {},
   "source": [
    "Pipeline starten"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18ecfe63",
   "metadata": {},
   "source": [
    "#### 3. Hide 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 501,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO -  2022-03-19 19:27:52,869: Pipeline gestartet.\n",
      "C:\\Users\\Max\\AppData\\Local\\Temp/ipykernel_13520/2112341696.py:28: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n",
      "  return pd.concat([temp.drop(['Prices_cut', 'Price_In_Eur_y'], 1), split_to_columns], axis=1).rename(columns={'Price_In_Eur_x' : 'Price_In_Eur'})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             Request_Date Flight_Date  Departure_hour    flight_unique_id  \\\n",
      "0     2019-06-03 11:00:00  2019-06-05              19   2019-06-05 FR 146   \n",
      "1     2019-06-03 23:00:00  2019-06-05              19   2019-06-05 FR 146   \n",
      "2     2019-06-04 11:00:00  2019-06-05              19   2019-06-05 FR 146   \n",
      "3     2019-06-04 23:00:00  2019-06-05              19   2019-06-05 FR 146   \n",
      "4     2019-06-03 11:00:00  2019-06-05              21   2019-06-05 FR 147   \n",
      "...                   ...         ...             ...                 ...   \n",
      "83619 2019-08-01 11:00:00  2019-09-10              10  2019-09-10 FR 8543   \n",
      "83620 2019-08-01 23:00:00  2019-09-10              10  2019-09-10 FR 8543   \n",
      "83621 2019-08-02 11:00:00  2019-09-10              10  2019-09-10 FR 8543   \n",
      "83622 2019-08-02 23:00:00  2019-09-10              10  2019-09-10 FR 8543   \n",
      "83623 2019-08-03 11:00:00  2019-09-10              10  2019-09-10 FR 8543   \n",
      "\n",
      "       Price_In_Eur  min_future_price_in_Eur  buy  last_departure  \\\n",
      "0            208.07                   259.07    1             0.0   \n",
      "1            259.07                   259.07    1             0.0   \n",
      "2            259.07                   259.07    1             0.0   \n",
      "3            259.07                   259.07    1             0.0   \n",
      "4            143.86                   251.72    1             0.0   \n",
      "...             ...                      ...  ...             ...   \n",
      "83619         35.69                    39.69    1             4.0   \n",
      "83620         46.83                    39.69    0             4.0   \n",
      "83621         46.83                    39.69    0             4.0   \n",
      "83622         39.69                    39.69    1             4.0   \n",
      "83623         39.69                    39.69    1             4.0   \n",
      "\n",
      "       next_departure  price_of_next_flight  ...       0       1       2  \\\n",
      "0                 3.0                 22.17  ...     NaN     NaN     NaN   \n",
      "1                 3.0                 22.17  ...  208.07     NaN     NaN   \n",
      "2                 3.0                 28.55  ...  208.07  259.07     NaN   \n",
      "3                 3.0                 50.99  ...  208.07  259.07  259.07   \n",
      "4                 9.0                171.49  ...     NaN     NaN     NaN   \n",
      "...               ...                   ...  ...     ...     ...     ...   \n",
      "83619             0.0                  0.00  ...   12.99   12.99   12.99   \n",
      "83620             0.0                  0.00  ...   12.99   12.99   29.57   \n",
      "83621             0.0                  0.00  ...   12.99   29.57   29.57   \n",
      "83622             0.0                  0.00  ...   29.57   29.57   29.57   \n",
      "83623             0.0                  0.00  ...   29.57   29.57   29.57   \n",
      "\n",
      "           3      4      5      6      7      8      9  \n",
      "0        NaN    NaN    NaN    NaN    NaN    NaN    NaN  \n",
      "1        NaN    NaN    NaN    NaN    NaN    NaN    NaN  \n",
      "2        NaN    NaN    NaN    NaN    NaN    NaN    NaN  \n",
      "3        NaN    NaN    NaN    NaN    NaN    NaN    NaN  \n",
      "4        NaN    NaN    NaN    NaN    NaN    NaN    NaN  \n",
      "...      ...    ...    ...    ...    ...    ...    ...  \n",
      "83619  29.57  29.57  29.57  29.57  35.69  35.69  35.69  \n",
      "83620  29.57  29.57  29.57  35.69  35.69  35.69  35.69  \n",
      "83621  29.57  29.57  35.69  35.69  35.69  35.69  46.83  \n",
      "83622  29.57  35.69  35.69  35.69  35.69  46.83  46.83  \n",
      "83623  35.69  35.69  35.69  35.69  46.83  46.83  39.69  \n",
      "\n",
      "[83624 rows x 27 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Max\\AppData\\Local\\Temp/ipykernel_13520/643847240.py:84: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n",
      "  data.drop(['Request_Date_w/o_Time'],1, inplace=True)\n",
      "C:\\Users\\Max\\AppData\\Local\\Temp/ipykernel_13520/643847240.py:109: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n",
      "  feiertage_diff_df = feiertage_diff_df.reset_index().drop('index', 1)\n",
      "INFO -  2022-03-19 19:48:19,213: Pipeline beendet.\n"
     ]
    }
   ],
   "source": [
    "last_n_requests = 10\n",
    "\n",
    "filename_train = os.path.join(dirname, '../Data/raw/train_set.csv')\n",
    "raw_data_train = pd.read_csv(filename_train, index_col=0)\n",
    "\n",
    "data_train = prep_data(raw_data_train, last_n_requests)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 502,
   "id": "f1c333cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO -  2022-03-19 19:48:19,350: Pipeline gestartet.\n",
      "C:\\Users\\Max\\AppData\\Local\\Temp/ipykernel_13520/2112341696.py:28: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n",
      "  return pd.concat([temp.drop(['Prices_cut', 'Price_In_Eur_y'], 1), split_to_columns], axis=1).rename(columns={'Price_In_Eur_x' : 'Price_In_Eur'})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Request_Date Flight_Date  Departure_hour    flight_unique_id  \\\n",
      "0    2019-06-03 11:00:00  2019-07-02               7   2019-07-02 FR 145   \n",
      "1    2019-06-03 23:00:00  2019-07-02               7   2019-07-02 FR 145   \n",
      "2    2019-06-04 11:00:00  2019-07-02               7   2019-07-02 FR 145   \n",
      "3    2019-06-04 23:00:00  2019-07-02               7   2019-07-02 FR 145   \n",
      "4    2019-06-05 11:00:00  2019-07-02               7   2019-07-02 FR 145   \n",
      "...                  ...         ...             ...                 ...   \n",
      "5578 2019-07-30 23:00:00  2019-08-02              22  2019-08-02 FR 8545   \n",
      "5579 2019-07-31 11:00:00  2019-08-02              22  2019-08-02 FR 8545   \n",
      "5580 2019-07-31 23:00:00  2019-08-02              22  2019-08-02 FR 8545   \n",
      "5581 2019-08-01 11:00:00  2019-08-02              22  2019-08-02 FR 8545   \n",
      "5582 2019-08-01 23:00:00  2019-08-02              22  2019-08-02 FR 8545   \n",
      "\n",
      "      Price_In_Eur  last_departure  next_departure  price_of_next_flight  \\\n",
      "0            30.32             0.0            12.0                 44.53   \n",
      "1            44.53             0.0            12.0                 58.69   \n",
      "2            44.47             0.0            12.0                 58.61   \n",
      "3            44.47             0.0            12.0                 58.61   \n",
      "4            44.52             0.0            12.0                 58.68   \n",
      "...            ...             ...             ...                   ...   \n",
      "5578         42.83             4.0             0.0                  0.00   \n",
      "5579         50.99             4.0             0.0                  0.00   \n",
      "5580         50.99             4.0             0.0                  0.00   \n",
      "5581         50.99             4.0             0.0                  0.00   \n",
      "5582         50.99             4.0             0.0                  0.00   \n",
      "\n",
      "      price_of_previous_flight  route_FRA-STN  ...      0      1      2  \\\n",
      "0                         0.00              0  ...    NaN    NaN    NaN   \n",
      "1                         0.00              0  ...  30.32    NaN    NaN   \n",
      "2                         0.00              0  ...  30.32  44.53    NaN   \n",
      "3                         0.00              0  ...  30.32  44.53  44.47   \n",
      "4                         0.00              0  ...  30.32  44.53  44.47   \n",
      "...                        ...            ...  ...    ...    ...    ...   \n",
      "5578                     42.83              0  ...  29.57  29.57  29.57   \n",
      "5579                     50.99              0  ...  29.57  29.57  35.69   \n",
      "5580                     50.99              0  ...  29.57  35.69  35.69   \n",
      "5581                     50.99              0  ...  35.69  35.69  35.69   \n",
      "5582                    211.13              0  ...  35.69  35.69  35.69   \n",
      "\n",
      "          3      4      5      6      7      8      9  \n",
      "0       NaN    NaN    NaN    NaN    NaN    NaN    NaN  \n",
      "1       NaN    NaN    NaN    NaN    NaN    NaN    NaN  \n",
      "2       NaN    NaN    NaN    NaN    NaN    NaN    NaN  \n",
      "3       NaN    NaN    NaN    NaN    NaN    NaN    NaN  \n",
      "4     44.47    NaN    NaN    NaN    NaN    NaN    NaN  \n",
      "...     ...    ...    ...    ...    ...    ...    ...  \n",
      "5578  35.69  35.69  35.69  35.69  35.69  35.69  42.83  \n",
      "5579  35.69  35.69  35.69  35.69  35.69  42.83  42.83  \n",
      "5580  35.69  35.69  35.69  35.69  42.83  42.83  50.99  \n",
      "5581  35.69  35.69  35.69  42.83  42.83  50.99  50.99  \n",
      "5582  35.69  35.69  42.83  42.83  50.99  50.99  50.99  \n",
      "\n",
      "[5583 rows x 25 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Max\\AppData\\Local\\Temp/ipykernel_13520/643847240.py:84: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n",
      "  data.drop(['Request_Date_w/o_Time'],1, inplace=True)\n",
      "C:\\Users\\Max\\AppData\\Local\\Temp/ipykernel_13520/643847240.py:109: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n",
      "  feiertage_diff_df = feiertage_diff_df.reset_index().drop('index', 1)\n",
      "INFO -  2022-03-19 19:48:53,524: Pipeline beendet.\n"
     ]
    }
   ],
   "source": [
    "filename_test = os.path.join(dirname, '../Data/raw/test_set.csv')\n",
    "raw_data_test = pd.read_csv(filename_test, index_col=0)\n",
    "\n",
    "data_test = prep_data(raw_data_test, last_n_requests, test=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a03de2ca",
   "metadata": {},
   "source": [
    "Bearbeitete Daten speichern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 503,
   "id": "80a47e98",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO -  2022-03-19 19:49:00,731: Datei gespeichernt.\n"
     ]
    }
   ],
   "source": [
    "filename = os.path.join(dirname, f'../Data/prepped/train_set_n{last_n_requests}.csv')\n",
    "\n",
    "if input(f'{filename} speichern? y/n') == \"y\":\n",
    "    data_train.to_csv(filename)\n",
    "    logging.info('Datei gespeichernt.')\n",
    "else:\n",
    "    logging.info('Nicht gespeichert.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 504,
   "id": "248e67c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO -  2022-03-19 19:49:02,590: Datei gespeichernt.\n"
     ]
    }
   ],
   "source": [
    "filename = os.path.join(dirname, f'../Data/prepped/test_set_n{last_n_requests}.csv')\n",
    "\n",
    "if input(f'{filename} speichern? y/n') == \"y\":\n",
    "    data_test.to_csv(filename)\n",
    "    logging.info('Datei gespeichernt.')\n",
    "else:\n",
    "    logging.info('Nicht gespeichert.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
