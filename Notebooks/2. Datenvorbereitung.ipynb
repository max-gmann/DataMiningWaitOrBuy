{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Flugpreis Vorhersage - Kaufen oder Warten?\n",
    "## Projektarbeit Data Mining\n",
    "___\n",
    "### Wintersemester 2021/22\n",
    "### Gruppe G:\n",
    "Max Grundmann - s0559326\n",
    "### Inhalte\n",
    "1. Problemanalyse\n",
    "2. Explorative Datenanalyse\n",
    "3. Weitere Features\n",
    "4. Praktische Überlegungen\n",
    "___\n",
    "## 1. Datenvorbereitung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.impute import SimpleImputer\n",
    "from numpy import asarray\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from datetime import datetime, timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dirname = os.getcwd()\n",
    "filename = os.path.join(dirname, '../Data/raw/train_set.csv')\n",
    "\n",
    "raw_data = pd.read_csv(filename, index_col=0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "d6fc4f92",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_delta_till_next_flight(df, forward=True):\n",
    "    temp = df.copy()\n",
    "\n",
    "    temp = temp.apply(lambda x: x['Flight_Date'] + timedelta(hours=x['Departure_hour']), axis=1)\n",
    "    temp = pd.DataFrame(temp)\n",
    "    temp = temp.sort_values(by=0, axis=0, ascending=forward)\n",
    "    temp = pd.DataFrame(temp[0].unique()).reset_index(drop=True)\n",
    "\n",
    "    if forward:\n",
    "        temp['delta'] = temp[0] - temp[0].shift()\n",
    "        column_name = 'last_departure'\n",
    "    else:\n",
    "        temp['delta'] = temp[0].shift() - temp[0]\n",
    "        column_name = 'next_departure'\n",
    "\n",
    "    temp['delta'] = temp['delta'].dt.seconds / 60 / 60\n",
    "    temp['delta'] = temp['delta'].fillna(0)\n",
    "    temp.rename(columns={ 0: 'Flight_Date_Time', 'delta' :column_name,}, inplace=True)\n",
    "\n",
    "    df_temp = df.copy()\n",
    "    df_temp['Flight_Date_Time'] = df_temp.apply(lambda x: x['Flight_Date'] + timedelta(hours=x['Departure_hour']), axis=1)\n",
    "    \n",
    "    return pd.merge(left=df_temp, right=temp, how='inner', on='Flight_Date_Time').drop(columns='Flight_Date_Time', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_price_history(df):\n",
    "    temp = df.copy()\n",
    "    temp = temp.sort_values(by='Request_Date', axis=0, ascending=True)\n",
    "    temp['Price_In_Eur'] = temp['Price_In_Eur'].astype(str)\n",
    "\n",
    "    price_history = temp.groupby(['flight_unique_id'])['Price_In_Eur'].apply(','.join).reset_index()\n",
    "    return price_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "418ec50d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_price_history(df):\n",
    "    prices = get_price_history(df)\n",
    "    temp = df.copy()\n",
    "    \n",
    "    split_to_columns = prices\n",
    "    split_to_columns['flight_unique_id'] = prices['flight_unique_id']\n",
    "\n",
    "    return pd.merge(left=temp, right=split_to_columns, how='left', on='flight_unique_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "768d6ed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_previous_requests(df):\n",
    "    temp = df.copy()\n",
    "    temp = temp.sort_values(['flight_unique_id', 'Request_Date'])\n",
    "    unique_flights = temp['flight_unique_id'].unique()\n",
    "\n",
    "    requests_counter = 0\n",
    "    flight_id_index = 0\n",
    "    current_flight = unique_flights[flight_id_index]\n",
    "    number_of_requests_per_row = []\n",
    "\n",
    "    for index, row in  temp.iterrows():\n",
    "        if row['flight_unique_id'] != current_flight:       \n",
    "            flight_id_index += 1\n",
    "            current_flight = unique_flights[flight_id_index]\n",
    "            requests_counter = 0\n",
    "        number_of_requests_per_row.append(requests_counter)\n",
    "        requests_counter += 1\n",
    "\n",
    "    temp['previous_requests'] = number_of_requests_per_row\n",
    "    return temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "d320bc82",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_last_n_prices(df, n=10):\n",
    "    last_n_requests = n\n",
    "    Prices = []\n",
    "    temp = df.copy()\n",
    "\n",
    "    for row in temp.itertuples():\n",
    "        row_prices = []\n",
    "        for i in range(row.previous_requests):\n",
    "            if len(row_prices) >= last_n_requests:\n",
    "                row_prices.pop(0)    \n",
    "            row_prices.append(getattr(row, 'Price_In_Eur_y').split(',')[i])\n",
    "        Prices.append(','.join(row_prices))\n",
    "\n",
    "    temp['Prices_cut'] = Prices\n",
    "    split_to_columns = temp['Prices_cut'].str.split(',', expand=True)\n",
    "    split_to_columns = split_to_columns.apply(pd.to_numeric)\n",
    "    split_to_columns.columns = split_to_columns.columns.map(str)\n",
    "\n",
    "    return pd.concat([temp.drop(['Prices_cut', 'Price_In_Eur_y'], 1), split_to_columns], axis=1).rename(columns={'Price_In_Eur_x' : 'Price_In_Eur'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_n_requests = 40\n",
    "\n",
    "def prep_data(data):\n",
    "    # Datentypen ändern\n",
    "    data['Flight_Date'] = pd.to_datetime(data['Flight_Date'])\n",
    "    data['Request_Date'] = pd.to_datetime(data['Request_Date'])\n",
    "    \n",
    "    # One Hot Encoding für Routen-Bezeichnungen\n",
    "    data = pd.get_dummies(data,prefix=['route'], columns = ['route_abb'], drop_first=False)\n",
    "    \n",
    "    # Flag, wenn die Anfrage die letzte Anfrage vor dem Flug ist\n",
    "    is_last_request = pd.DataFrame(data.groupby('flight_unique_id')['Request_Date'].max()).reset_index()\n",
    "    is_last_request['is_last_request'] = 1\n",
    "\n",
    "    data = data.merge(is_last_request, \n",
    "                      on=['flight_unique_id', 'Request_Date'], \n",
    "                      how='left')\n",
    "    data['is_last_request'] = data['is_last_request'].fillna(0)\n",
    "    data['is_last_request'] = data['is_last_request'].astype(int)\n",
    "    \n",
    "    # Abstand zu letztem und nächsten Flug berechnen\n",
    "    forward = calculate_delta_till_next_flight(data, forward=True).reset_index(drop=True)\n",
    "    backward = calculate_delta_till_next_flight(forward, forward=False)\n",
    "    data = backward\n",
    "\n",
    "    # Anzahl der bisherigen Requests als Feature hinzufügen\n",
    "    data = get_previous_requests(data)\n",
    "    \n",
    "    # Preishistorie berechnen\n",
    "    data = merge_price_history(data)\n",
    "    data = get_last_n_prices(data, last_n_requests)\n",
    "\n",
    "    # Datumsfelder in einzelne Bestandteile zerlegen\n",
    "    data['flight_weekday'] = data['Flight_Date'].dt.weekday\n",
    "    data['flight_day'] = data['Flight_Date'].dt.day\n",
    "    data['flight_month'] = data['Flight_Date'].dt.month \n",
    "    data['flight_is_weekend'] = data['flight_weekday'] >= 5\n",
    "\n",
    "    data['request_weekday'] = data['Request_Date'].dt.weekday\n",
    "    data['request_day'] = data['Request_Date'].dt.day\n",
    "    data['request_month'] = data['Request_Date'].dt.month\n",
    "    data['request_is_weekend'] = data['request_weekday'] >= 5\n",
    "    \n",
    "    data['request_hour'] = data['Request_Date'].dt.hour\n",
    "    \n",
    "    # Cyclische Features in Sinus und Cosinus Repräsentation umwandeln\n",
    "    # Quelle: https://www.mikulskibartosz.name/time-in-machine-learning/\n",
    "    def encode(data, col, max_val):\n",
    "        data[col + '_sin'] = np.sin(2 * np.pi * data[col]/max_val)\n",
    "        data[col + '_cos'] = np.cos(2 * np.pi * data[col]/max_val)\n",
    "        return data\n",
    "\n",
    "    data = encode(data, 'request_weekday', 7)\n",
    "    data = encode(data, 'request_month', 12)\n",
    "    data = encode(data, 'request_day', 365)\n",
    "    data = encode(data, 'request_hour', 24)\n",
    "\n",
    "    data = encode(data, 'flight_weekday', 7)\n",
    "    data = encode(data, 'flight_month', 12)\n",
    "    data = encode(data, 'flight_day', 365)\n",
    "    data = encode(data, 'Departure_hour', 24)\n",
    "    \n",
    "    # Tage bis zum Flug berechnen\n",
    "    data['Request_Date_w/o_Time'] = pd.to_datetime(data['Request_Date']).dt.date\n",
    "    data['days_remaining'] = (pd.to_datetime(data['Flight_Date']).dt.date - data['Request_Date_w/o_Time']).dt.days\n",
    "    data.drop(['Request_Date_w/o_Time'],1, inplace=True)\n",
    "    \n",
    "    # Relevante Feiertage im Zeitraum der Daten, die in Berlin und oder Frankfurt gelten\n",
    "    # sowie Public Holidays in Großbritannien. \n",
    "    feiertage = {\n",
    "        '2019-06-09':'Pfingstsonntag',\n",
    "        '2019-06-10':'Pfingstmontag',\n",
    "        '2019-06-20':'Fronleichnam',\n",
    "        '2019-06-20':'Schulferien Beginn',\n",
    "        '2019-08-02':'Schulferien Ende',\n",
    "        '2019-08-26':'Summer Bank Holidays',\n",
    "        '2019-07-15':'School Summer Holidays Beginn',\n",
    "        '2019-09-06':'School Summer Holidays End'}\n",
    "\n",
    "    feiertage_df = pd.DataFrame(feiertage.items(), columns=['Datum_Feiertag', 'Feiertag_Bezeichnung'])\n",
    "    feiertage_df['Datum_Feiertag'] = pd.to_datetime(feiertage_df['Datum_Feiertag'])\n",
    "    \n",
    "    from datetime import datetime\n",
    "\n",
    "    day_diff_list = []\n",
    "    for index, row in feiertage_df.iterrows():\n",
    "        day_diff_list.append(abs((data['Flight_Date'] - row['Datum_Feiertag']).dt.days))\n",
    "        \n",
    "    feiertage_diff_df = pd.concat(day_diff_list, axis=1)\n",
    "    feiertage_diff_df = feiertage_diff_df.min(axis=1)\n",
    "    feiertage_diff_df = feiertage_diff_df.reset_index().drop('index', 1)\n",
    "    feiertage_diff_df.columns = ['Days_Untill_Event']\n",
    "\n",
    "    data = pd.concat([data, feiertage_diff_df], axis=1)\n",
    "\n",
    "    # Features skalieren\n",
    "    scaler = MinMaxScaler()\n",
    "    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
    "    dont_scale = ['buy', 'is_last_request']\n",
    "    to_be_scaled = data.select_dtypes(include=numerics).drop(dont_scale, axis=1)\n",
    "    data.drop(to_be_scaled.columns, axis=1, inplace=True)\n",
    "    scaled = pd.DataFrame(scaler.fit_transform(to_be_scaled), columns=to_be_scaled.columns)\n",
    "    data = pd.concat([data.reset_index(), scaled.reset_index()], axis=1)\n",
    "    \n",
    "    # Nicht mehr benötigte Spalten entfernen\n",
    "    data.drop(['Request_Date', \n",
    "               'Flight_Date', \n",
    "               'min_future_price_in_Eur', \n",
    "               'index', \n",
    "               'Departure_hour', \n",
    "               'flight_weekday', \n",
    "               'flight_day', \n",
    "               'flight_month', \n",
    "               'request_weekday', \n",
    "               'request_day', \n",
    "               'request_month', \n",
    "            #    'days_remaining',\n",
    "               'request_hour', \n",
    "            #    'Days_Untill_Event',\n",
    "            #    'previous_requests',\n",
    "               'flight_unique_id'], inplace=True, axis=1)\n",
    "    \n",
    "    # Boolean in Int umwandeln\n",
    "    data['request_is_weekend'] = data['request_is_weekend'].astype(int)\n",
    "    data['flight_is_weekend'] = data['flight_is_weekend'].astype(int)\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Max\\AppData\\Local\\Temp/ipykernel_1520/4150257830.py:19: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n",
      "  return pd.concat([temp.drop(['Prices_cut', 'Price_In_Eur_y'], 1), split_to_columns], axis=1).rename(columns={'Price_In_Eur_x' : 'Price_In_Eur'})\n",
      "C:\\Users\\Max\\AppData\\Local\\Temp/ipykernel_1520/488601033.py:66: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n",
      "  data.drop(['Request_Date_w/o_Time'],1, inplace=True)\n",
      "C:\\Users\\Max\\AppData\\Local\\Temp/ipykernel_1520/488601033.py:91: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n",
      "  feiertage_diff_df = feiertage_diff_df.reset_index().drop('index', 1)\n"
     ]
    }
   ],
   "source": [
    "data = prep_data(raw_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "80a47e98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datei gespeichernt.\n"
     ]
    }
   ],
   "source": [
    "filename = os.path.join(dirname, f'../Data/prepped/train_set_n{last_n_requests}.csv')\n",
    "\n",
    "if input('Datei speichern? y/n') == \"y\":\n",
    "    data.to_csv(filename)\n",
    "    print('Datei gespeichernt.')\n",
    "else:\n",
    "    print('Nicht gespeichert.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
