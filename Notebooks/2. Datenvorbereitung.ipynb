{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ddafb041",
   "metadata": {},
   "source": [
    "# Flugpreis Vorhersage - Kaufen oder Warten?\n",
    "## Projektarbeit Data Mining\n",
    "___\n",
    "### Wintersemester 2021/22\n",
    "### Gruppe G:\n",
    "Max Grundmann - s0559326\n",
    "### Inhalte\n",
    "1. Exploratory Data Analysis (EDA)\n",
    "### 2. Datenvorbereitung\n",
    "3. Modelauswahl\n",
    "4. Testing\n",
    "___\n",
    "Dieses Notebook implementiert die nötigen Schritte zur Transformation der Daten, Feature Engineering und -generierung und wendet sie auf die Trainings- und Testdaten an, um sie für das Training vorzubereiten.\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "031ce98b",
   "metadata": {},
   "source": [
    "Benötigte Bibliotheken importieren"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "68f75b4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from numpy import asarray\n",
    "from datetime import datetime, timedelta\n",
    "import logging\n",
    "import tqdm\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0efab602",
   "metadata": {},
   "source": [
    "Dateipfade festlegen "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "455ac42e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "logging.basicConfig(level=logging.INFO, format='%(levelname)s -  %(asctime)s: %(message)s')\n",
    "\n",
    "dirname = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "81690680",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_price_history(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Generiert die Preishistorie für alle Flüge in einem Dataframe und verkettet sie in einem Feld.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): Input Dataframe\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Output Dataframe mit Preishistorie.\n",
    "    \"\"\"\n",
    "    temp = df.copy()\n",
    "    temp = temp.sort_values(by='Request_Date', axis=0, ascending=True)\n",
    "    temp['Price_In_Eur'] = temp['Price_In_Eur'].astype(str)\n",
    "\n",
    "    price_history = temp.groupby(['flight_unique_id'])['Price_In_Eur'].apply(','.join).reset_index()\n",
    "    return price_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "418ec50d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_price_history(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Führt die Daten mit der generierten Preishistorie zusammen.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): Input Dataframe\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Output Dataframe mit Preishistorie\n",
    "    \"\"\"\n",
    "    prices = get_price_history(df)\n",
    "    temp = df.copy()\n",
    "    \n",
    "    split_to_columns = prices\n",
    "    split_to_columns['flight_unique_id'] = prices['flight_unique_id']\n",
    "\n",
    "    return pd.merge(left=temp, right=split_to_columns, how='left', on='flight_unique_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "768d6ed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_previous_requests(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Findet die Anzahl vorheriger Anfragen für eine gegebene FlightID\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): Input Dataframe\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Output Dataframe mit Spalte Anzahl vorheriger Anfragen\n",
    "    \"\"\"\n",
    "    temp = df.copy()\n",
    "    temp = temp.sort_values(['flight_unique_id', 'Request_Date'])\n",
    "    unique_flights = temp['flight_unique_id'].unique()\n",
    "\n",
    "    requests_counter = 0\n",
    "    flight_id_index = 0\n",
    "    current_flight = unique_flights[flight_id_index]\n",
    "    number_of_requests_per_row = []\n",
    "\n",
    "    for index, row in  temp.iterrows():\n",
    "        if row['flight_unique_id'] != current_flight:       \n",
    "            flight_id_index += 1\n",
    "            current_flight = unique_flights[flight_id_index]\n",
    "            requests_counter = 0\n",
    "        number_of_requests_per_row.append(requests_counter)\n",
    "        requests_counter += 1\n",
    "\n",
    "    temp['previous_requests'] = number_of_requests_per_row\n",
    "    return temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "8f5f6210",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_price_of_closest_flight(df: pd.DataFrame, new_name:str, fill_with_column: str, previous: bool =False) -> pd.DataFrame:\n",
    "    \"\"\"Liefert den Preis des jeweils dichtesten Fluges der selben Strecke zurück.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): Input Dataframe\n",
    "        new_name (str): Name der neuen Spalte\n",
    "        fill_with_column (str): Name der Spalte die den relevanten Wert enthält\n",
    "        previous (bool, optional): Richtung der Berechnung. Defaults to False.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Output Dataframe\n",
    "    \"\"\"\n",
    "    temp = df.copy()\n",
    "\n",
    "    temp['Flight_Date_Time'] = temp.apply(lambda x: x['Flight_Date'] + timedelta(hours=x['Departure_hour']), axis=1)\n",
    "    temp = temp.sort_values(['route_abb', 'Flight_Date_Time'], axis=0)\n",
    "\n",
    "    routen = temp['route_abb'].unique()\n",
    "    df_list = []\n",
    "\n",
    "    temp[new_name] = 0.0\n",
    "\n",
    "    for route in routen:\n",
    "        subset = temp[temp['route_abb'] == route].reset_index(drop=True)\n",
    "\n",
    "        for index, row in subset.iterrows():\n",
    "            f1 = subset[subset['flight_unique_id'] != row['flight_unique_id']] \n",
    "\n",
    "            if previous:\n",
    "                f2 = f1[f1['Flight_Date_Time'] <= row['Flight_Date_Time']]\n",
    "                f3 = f2[f2['Request_Date'] >= row['Request_Date']]\n",
    "            else:\n",
    "                f2 = f1[f1['Flight_Date_Time'] >= row['Flight_Date_Time']]\n",
    "                f3 = f2[f2['Request_Date'] >= row['Request_Date']]\n",
    "                \n",
    "            f4 = f3.sort_values(['Flight_Date_Time', 'Request_Date'])\n",
    "\n",
    "            if index >= len(f4):\n",
    "                if len(f4) == 0:\n",
    "                    subset.at[index, new_name] = 0\n",
    "                else:\n",
    "                    subset.at[index, new_name] = f4[fill_with_column].iloc[0] \n",
    "            else:    \n",
    "                subset.at[index, new_name] = f4[fill_with_column].iloc[0] \n",
    "        \n",
    "        df_list.append(subset)\n",
    "    return pd.concat(df_list).reset_index(drop=True).drop(['Flight_Date_Time'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "d6fc4f92",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_delta_till_next_flight(df: pd.DataFrame, forward: bool=True) -> pd.DataFrame:\n",
    "    \"\"\"Diese Funktion berechnet die Zeit bis zum nächsten Flug der selben FlightID.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): Input Dataframe\n",
    "        forward (bool, optional): Bestimmt die Richtung der Berechnung. Defaults to True.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: _description_\n",
    "    \"\"\"\n",
    "    temp = df.copy()\n",
    "    org = df.copy()\n",
    "\n",
    "    temp['Departure_Time'] = temp.apply(lambda x: x['Flight_Date'] + timedelta(hours=x['Departure_hour']), axis=1)\n",
    "    org['Flight_Date_Time'] = org.apply(lambda x: x['Flight_Date'] + timedelta(hours=x['Departure_hour']), axis=1)\n",
    "    \n",
    "    temp = temp.sort_values(by=['route_abb', 'Departure_Time'], axis=0, ascending=forward)\n",
    "    routen = temp['route_abb'].unique()\n",
    "\n",
    "    sorted_df = temp\n",
    "    df_list = []\n",
    "\n",
    "    for route in routen:\n",
    "        temp = sorted_df[sorted_df['route_abb'] == route]\n",
    "        temp = pd.DataFrame(temp[['Departure_Time', 'route_abb']])\n",
    "        temp = temp.drop_duplicates()\n",
    "        temp.rename(columns={ 'Departure_Time': 0}, inplace=True)\n",
    "\n",
    "        if forward:\n",
    "            temp['delta'] = temp[0] - temp[0].shift()\n",
    "            column_name = 'last_departure'\n",
    "        else:\n",
    "            temp['delta'] = temp[0].shift() - temp[0]\n",
    "            column_name = 'next_departure'\n",
    "\n",
    "        temp['delta'] = temp['delta'].dt.seconds / 60 / 60\n",
    "        temp['delta'] = temp['delta'].fillna(0)\n",
    "        temp.rename(columns={ 0: 'Flight_Date_Time', 'delta' :column_name,}, inplace=True)\n",
    "        \n",
    "        df_list.append(temp)\n",
    "\n",
    "    mapping = pd.concat(df_list)\n",
    "\n",
    "    mapping = mapping.dropna()\n",
    "\n",
    "    org = pd.merge(left=org, right=mapping, how='inner', on=['Flight_Date_Time', 'route_abb'])\n",
    "\n",
    "    return org.drop(columns='Flight_Date_Time', axis=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "d320bc82",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_last_n_prices(df: pd.DataFrame, n:int =10) -> pd.DataFrame:\n",
    "    \"\"\"Liefert die Preishistorie für eine gegebene Anzahl an historischen Anfragen.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): Input Dataframe\n",
    "        n (int, optional): Anzahl an historischen Preisen. Defaults to 10.\n",
    "\n",
    "    Returns:\n",
    "        (pd.DataFrame): Output Dataframe mit Preishistorie\n",
    "    \"\"\"\n",
    "    last_n_requests = n\n",
    "    Prices = []\n",
    "    temp = df.copy()\n",
    "\n",
    "    for row in temp.itertuples():\n",
    "        row_prices = []\n",
    "        for i in range(row.previous_requests):\n",
    "            if len(row_prices) >= last_n_requests:\n",
    "                row_prices.pop(0)    \n",
    "            row_prices.append(getattr(row, 'Price_In_Eur_y').split(',')[i])\n",
    "        Prices.append(','.join(row_prices))\n",
    "\n",
    "    temp['Prices_cut'] = Prices\n",
    "    split_to_columns = temp['Prices_cut'].str.split(',', expand=True)\n",
    "    split_to_columns = split_to_columns.apply(pd.to_numeric)\n",
    "    split_to_columns.columns = split_to_columns.columns.map(str)\n",
    "\n",
    "    return pd.concat([temp.drop(['Prices_cut', 'Price_In_Eur_y'], 1), split_to_columns], axis=1).rename(columns={'Price_In_Eur_x' : 'Price_In_Eur'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "a6befd43",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_data(data: pd.DataFrame, last_n_requests: int, test: bool = False) -> pd.DataFrame:\n",
    "    \"\"\"Wendet die benötigten Transformationen auf die Rohdaten an und gibt ein fertiges DataFrame für das Training zurück.\n",
    "\n",
    "    Args:\n",
    "        data (pd.DataFrame): Input Dataframe\n",
    "        last_n_requests (int): Anzahl Schritte die die Preishistorie zurückgeht\n",
    "        test (bool): Test- oder Trainingsset\n",
    "    Returns:\n",
    "        pd.DataFrame: Output Dataframe\n",
    "    \"\"\"\n",
    "    \n",
    "    logging.info('Pipeline gestartet.')\n",
    "    \n",
    "    # Zum sortieren des Dataframes\n",
    "    data.insert(0, 'row_id', range(0, len(data)))\n",
    "\n",
    "    # Datentypen ändern\n",
    "    data['Flight_Date'] = pd.to_datetime(data['Flight_Date'])\n",
    "    data['Request_Date'] = pd.to_datetime(data['Request_Date']).dt.tz_localize(None)\n",
    "    \n",
    "    # Abstand zu letztem und nächsten Flug berechnen\n",
    "    forward = calculate_delta_till_next_flight(data, forward=True).reset_index(drop=True)\n",
    "    backward = calculate_delta_till_next_flight(forward, forward=False)\n",
    "    data = backward\n",
    "\n",
    "    # Preis des dichtesten letzten und nächsten Fluges berechnen\n",
    "    data = get_price_of_closest_flight(data, 'price_of_next_flight', 'Price_In_Eur')\n",
    "    data = get_price_of_closest_flight(data, 'price_of_previous_flight', 'Price_In_Eur', previous=True)\n",
    "\n",
    "    # One Hot Encoding für Routen-Bezeichnungen\n",
    "    data = pd.get_dummies(data,prefix=['route'], columns = ['route_abb'], drop_first=False)\n",
    "    \n",
    "    # Flag, wenn die Anfrage die letzte Anfrage vor dem Flug ist\n",
    "    is_last_request = pd.DataFrame(data.groupby('flight_unique_id')['Request_Date'].max()).reset_index()\n",
    "    is_last_request['is_last_request'] = 1\n",
    "\n",
    "    data = data.merge(is_last_request, \n",
    "                      on=['flight_unique_id', 'Request_Date'], \n",
    "                      how='left')\n",
    "    data['is_last_request'] = data['is_last_request'].fillna(0)\n",
    "    data['is_last_request'] = data['is_last_request'].astype(int)\n",
    "    \n",
    "    # Anzahl der bisherigen Requests als Feature hinzufügen\n",
    "    data = get_previous_requests(data)\n",
    "    \n",
    "    # Preishistorie berechnen\n",
    "    data = merge_price_history(data)\n",
    "    data = get_last_n_prices(data, last_n_requests)\n",
    "\n",
    "    # Preisänderung zur letzten Abfrage in %\n",
    "    data['PriceChange'] = data.apply(\n",
    "        lambda row:( (row['Price_In_Eur'] / row[str(last_n_requests-1)] )-1 if (row['previous_requests'] >= last_n_requests or row['previous_requests'] == 0) else (row['Price_In_Eur'] / row[ str(row['previous_requests'] -1) ]) - 1), axis=1)\n",
    "\n",
    "    # Datumsfelder in einzelne Bestandteile zerlegen\n",
    "    data['flight_weekday'] = data['Flight_Date'].dt.weekday\n",
    "    data['flight_day'] = data['Flight_Date'].dt.day\n",
    "    data['flight_month'] = data['Flight_Date'].dt.month \n",
    "    data['flight_is_weekend'] = data['flight_weekday'] >= 5\n",
    "\n",
    "    data['request_weekday'] = data['Request_Date'].dt.weekday\n",
    "    data['request_day'] = data['Request_Date'].dt.day\n",
    "    data['request_month'] = data['Request_Date'].dt.month\n",
    "    data['request_is_weekend'] = data['request_weekday'] >= 5\n",
    "    \n",
    "    data['request_hour'] = data['Request_Date'].dt.hour\n",
    "    \n",
    "    # Cyclische Features in Sinus und Cosinus Repräsentation umwandeln\n",
    "    # Quelle: https://www.mikulskibartosz.name/time-in-machine-learning/\n",
    "    def encode(data, col, max_val):\n",
    "        data[col + '_sin'] = np.sin(2 * np.pi * data[col]/max_val)\n",
    "        data[col + '_cos'] = np.cos(2 * np.pi * data[col]/max_val)\n",
    "        return data\n",
    "\n",
    "    data = encode(data, 'request_weekday', 7)\n",
    "    data = encode(data, 'request_month', 12)\n",
    "    data = encode(data, 'request_day', 365)\n",
    "    data = encode(data, 'request_hour', 24)\n",
    "\n",
    "    data = encode(data, 'flight_weekday', 7)\n",
    "    data = encode(data, 'flight_month', 12)\n",
    "    data = encode(data, 'flight_day', 365)\n",
    "    data = encode(data, 'Departure_hour', 24)\n",
    "    \n",
    "    # Tage bis zum Flug berechnen\n",
    "    data['Request_Date_w/o_Time'] = pd.to_datetime(data['Request_Date']).dt.date\n",
    "    data['days_remaining'] = (pd.to_datetime(data['Flight_Date']).dt.date - data['Request_Date_w/o_Time']).dt.days\n",
    "    data.drop(['Request_Date_w/o_Time'],1, inplace=True)\n",
    "    \n",
    "    # Relevante Feiertage im Zeitraum der Daten, die in Berlin und oder Frankfurt gelten\n",
    "    # sowie Public Holidays in Großbritannien. \n",
    "    feiertage = {\n",
    "        '2019-06-09':'Pfingstsonntag',\n",
    "        '2019-06-10':'Pfingstmontag',\n",
    "        '2019-06-20':'Fronleichnam',\n",
    "        '2019-06-20':'Schulferien Beginn',\n",
    "        '2019-08-02':'Schulferien Ende',\n",
    "        '2019-08-26':'Summer Bank Holidays',\n",
    "        '2019-07-15':'School Summer Holidays Beginn',\n",
    "        '2019-09-06':'School Summer Holidays End'}\n",
    "\n",
    "    feiertage_df = pd.DataFrame(feiertage.items(), columns=['Datum_Feiertag', 'Feiertag_Bezeichnung'])\n",
    "    feiertage_df['Datum_Feiertag'] = pd.to_datetime(feiertage_df['Datum_Feiertag'])\n",
    "    \n",
    "    from datetime import datetime\n",
    "\n",
    "    day_diff_list = []\n",
    "    for index, row in feiertage_df.iterrows():\n",
    "        day_diff_list.append(abs((data['Flight_Date'] - row['Datum_Feiertag']).dt.days))\n",
    "        \n",
    "    feiertage_diff_df = pd.concat(day_diff_list, axis=1)\n",
    "    feiertage_diff_df = feiertage_diff_df.min(axis=1)\n",
    "    feiertage_diff_df = feiertage_diff_df.reset_index().drop('index', 1)\n",
    "    feiertage_diff_df.columns = ['Days_Untill_Event']\n",
    "\n",
    "    data = pd.concat([data, feiertage_diff_df], axis=1)\n",
    "\n",
    "    try:\n",
    "        data.drop(['index'], axis=1, inplace=True)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    # Features skalieren\n",
    "    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
    "    dont_scale = ['is_last_request', 'row_id']\n",
    "    if not test: \n",
    "        dont_scale.append('buy')\n",
    "        dont_scale.append('min_future_price_in_Eur')\n",
    "    to_be_scaled = data.select_dtypes(include=numerics).drop(dont_scale, axis=1)\n",
    "    data.drop(to_be_scaled.columns, axis=1, inplace=True)\n",
    "    \n",
    "    if not test:\n",
    "        scaler = MinMaxScaler()\n",
    "        scaled = pd.DataFrame(scaler.fit_transform(to_be_scaled), columns=to_be_scaled.columns)\n",
    "        joblib.dump(scaler, '../Models/Scalers/minmax.gz')\n",
    "    else:\n",
    "        scaler = joblib.load('../Models/Scalers/minmax.gz')\n",
    "        scaled = pd.DataFrame(scaler.transform(to_be_scaled), columns=to_be_scaled.columns)\n",
    "\n",
    "    data = pd.concat([data.reset_index(), scaled.reset_index()], axis=1)\n",
    "    \n",
    "    # Dataframe wieder in ursprüngliche Reihenfolge bringen\n",
    "    data = data.sort_values('row_id')\n",
    "\n",
    "    # Nicht mehr benötigte Spalten entfernen\n",
    "    drop_list = ['Request_Date', \n",
    "               'Flight_Date',  \n",
    "            #    'index', \n",
    "               'Departure_hour', \n",
    "               'flight_weekday', \n",
    "               'flight_day', \n",
    "               'row_id',\n",
    "               'flight_month', \n",
    "               'request_weekday', \n",
    "               'request_day', \n",
    "               'request_month', \n",
    "            #    'days_remaining',\n",
    "               'request_hour', \n",
    "            #    'Days_Untill_Event',\n",
    "            #    'previous_requests',\n",
    "               'flight_unique_id']\n",
    "    if not test: drop_list.append('min_future_price_in_Eur')\n",
    "    data.drop(drop_list, inplace=True, axis=1)\n",
    "    \n",
    "    # Boolean in Int umwandeln\n",
    "    data['request_is_weekend'] = data['request_is_weekend'].astype(int)\n",
    "    data['flight_is_weekend'] = data['flight_is_weekend'].astype(int)\n",
    "    \n",
    "    try:\n",
    "        data.drop(['index'], axis=1, inplace=True)\n",
    "        data.drop(['index'], axis=1, inplace=True)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    logging.info('Pipeline beendet.')\n",
    "    return data.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3024cd6b",
   "metadata": {},
   "source": [
    "Pipeline starten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "f7d02b88",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO -  2022-03-20 11:11:31,987: Pipeline gestartet.\n",
      "C:\\Users\\Max\\AppData\\Local\\Temp/ipykernel_6160/2112341696.py:28: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n",
      "  return pd.concat([temp.drop(['Prices_cut', 'Price_In_Eur_y'], 1), split_to_columns], axis=1).rename(columns={'Price_In_Eur_x' : 'Price_In_Eur'})\n",
      "C:\\Users\\Max\\AppData\\Local\\Temp/ipykernel_6160/2785060161.py:87: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n",
      "  data.drop(['Request_Date_w/o_Time'],1, inplace=True)\n",
      "C:\\Users\\Max\\AppData\\Local\\Temp/ipykernel_6160/2785060161.py:112: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n",
      "  feiertage_diff_df = feiertage_diff_df.reset_index().drop('index', 1)\n",
      "INFO -  2022-03-20 11:31:46,537: Pipeline beendet.\n"
     ]
    }
   ],
   "source": [
    "last_n_requests = 15\n",
    "\n",
    "filename_train = os.path.join(dirname, '../Data/raw/train_set.csv')\n",
    "raw_data_train = pd.read_csv(filename_train, index_col=0)\n",
    "\n",
    "data_train = prep_data(raw_data_train, last_n_requests)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "f1c333cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO -  2022-03-20 11:31:46,712: Pipeline gestartet.\n",
      "C:\\Users\\Max\\AppData\\Local\\Temp/ipykernel_6160/2112341696.py:28: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n",
      "  return pd.concat([temp.drop(['Prices_cut', 'Price_In_Eur_y'], 1), split_to_columns], axis=1).rename(columns={'Price_In_Eur_x' : 'Price_In_Eur'})\n",
      "C:\\Users\\Max\\AppData\\Local\\Temp/ipykernel_6160/2785060161.py:87: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n",
      "  data.drop(['Request_Date_w/o_Time'],1, inplace=True)\n",
      "C:\\Users\\Max\\AppData\\Local\\Temp/ipykernel_6160/2785060161.py:112: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n",
      "  feiertage_diff_df = feiertage_diff_df.reset_index().drop('index', 1)\n",
      "INFO -  2022-03-20 11:32:19,691: Pipeline beendet.\n"
     ]
    }
   ],
   "source": [
    "filename_test = os.path.join(dirname, '../Data/raw/test_set.csv')\n",
    "raw_data_test = pd.read_csv(filename_test, index_col=0)\n",
    "\n",
    "data_test = prep_data(raw_data_test, last_n_requests, test=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a03de2ca",
   "metadata": {},
   "source": [
    "Bearbeitete Daten speichern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "80a47e98",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO -  2022-03-20 11:44:39,253: Datei gespeichernt.\n"
     ]
    }
   ],
   "source": [
    "filename = os.path.join(dirname, f'../Data/prepped/train_set_n{last_n_requests}.csv')\n",
    "\n",
    "if input(f'{filename} speichern? y/n') == \"y\":\n",
    "    data_train.to_csv(filename)\n",
    "    logging.info('Datei gespeichernt.')\n",
    "else:\n",
    "    logging.info('Nicht gespeichert.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "248e67c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO -  2022-03-20 11:44:40,589: Datei gespeichernt.\n"
     ]
    }
   ],
   "source": [
    "filename = os.path.join(dirname, f'../Data/prepped/test_set_n{last_n_requests}.csv')\n",
    "\n",
    "if input(f'{filename} speichern? y/n') == \"y\":\n",
    "    data_test.to_csv(filename)\n",
    "    logging.info('Datei gespeichernt.')\n",
    "else:\n",
    "    logging.info('Nicht gespeichert.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
