{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Flugpreis Vorhersage - Kaufen oder Warten?\n",
    "## Projektarbeit Data Mining\n",
    "___\n",
    "### Wintersemester 2021/22\n",
    "### Gruppe G:\n",
    "Max Grundmann - s0559326\n",
    "### Inhalte\n",
    "1. Problemanalyse\n",
    "2. Explorative Datenanalyse\n",
    "3. Weitere Features\n",
    "4. Praktische Ãœberlegungen\n",
    "___\n",
    "## 1. Datenvorbereitung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.impute import SimpleImputer\n",
    "from numpy import asarray\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dirname = os.getcwd()\n",
    "filename = os.path.join(dirname, '../Data/train_set.csv')\n",
    "\n",
    "data = pd.read_csv(filename, index_col=0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Request_Date</th>\n",
       "      <th>Flight_Date</th>\n",
       "      <th>Departure_hour</th>\n",
       "      <th>flight_unique_id</th>\n",
       "      <th>route_abb</th>\n",
       "      <th>Price_In_Eur</th>\n",
       "      <th>min_future_price_in_Eur</th>\n",
       "      <th>buy</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-06-03T11:00:00Z</td>\n",
       "      <td>2019-06-05</td>\n",
       "      <td>19</td>\n",
       "      <td>2019-06-05 FR 146</td>\n",
       "      <td>SXF-STN</td>\n",
       "      <td>208.07</td>\n",
       "      <td>259.07</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-06-03T23:00:00Z</td>\n",
       "      <td>2019-06-05</td>\n",
       "      <td>19</td>\n",
       "      <td>2019-06-05 FR 146</td>\n",
       "      <td>SXF-STN</td>\n",
       "      <td>259.07</td>\n",
       "      <td>259.07</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-06-04T11:00:00Z</td>\n",
       "      <td>2019-06-05</td>\n",
       "      <td>19</td>\n",
       "      <td>2019-06-05 FR 146</td>\n",
       "      <td>SXF-STN</td>\n",
       "      <td>259.07</td>\n",
       "      <td>259.07</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-06-04T23:00:00Z</td>\n",
       "      <td>2019-06-05</td>\n",
       "      <td>19</td>\n",
       "      <td>2019-06-05 FR 146</td>\n",
       "      <td>SXF-STN</td>\n",
       "      <td>259.07</td>\n",
       "      <td>259.07</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2019-06-03T11:00:00Z</td>\n",
       "      <td>2019-06-05</td>\n",
       "      <td>21</td>\n",
       "      <td>2019-06-05 FR 147</td>\n",
       "      <td>STN-SXF</td>\n",
       "      <td>143.86</td>\n",
       "      <td>251.72</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2019-06-03T23:00:00Z</td>\n",
       "      <td>2019-06-05</td>\n",
       "      <td>21</td>\n",
       "      <td>2019-06-05 FR 147</td>\n",
       "      <td>STN-SXF</td>\n",
       "      <td>252.06</td>\n",
       "      <td>251.72</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2019-06-04T11:00:00Z</td>\n",
       "      <td>2019-06-05</td>\n",
       "      <td>21</td>\n",
       "      <td>2019-06-05 FR 147</td>\n",
       "      <td>STN-SXF</td>\n",
       "      <td>251.72</td>\n",
       "      <td>251.72</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2019-06-04T23:00:00Z</td>\n",
       "      <td>2019-06-05</td>\n",
       "      <td>21</td>\n",
       "      <td>2019-06-05 FR 147</td>\n",
       "      <td>STN-SXF</td>\n",
       "      <td>251.72</td>\n",
       "      <td>251.72</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2019-06-03T11:00:00Z</td>\n",
       "      <td>2019-06-05</td>\n",
       "      <td>22</td>\n",
       "      <td>2019-06-05 FR 8545</td>\n",
       "      <td>SXF-STN</td>\n",
       "      <td>22.17</td>\n",
       "      <td>22.17</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2019-06-03T23:00:00Z</td>\n",
       "      <td>2019-06-05</td>\n",
       "      <td>22</td>\n",
       "      <td>2019-06-05 FR 8545</td>\n",
       "      <td>SXF-STN</td>\n",
       "      <td>22.17</td>\n",
       "      <td>28.55</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2019-06-04T11:00:00Z</td>\n",
       "      <td>2019-06-05</td>\n",
       "      <td>22</td>\n",
       "      <td>2019-06-05 FR 8545</td>\n",
       "      <td>SXF-STN</td>\n",
       "      <td>28.55</td>\n",
       "      <td>50.99</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2019-06-04T23:00:00Z</td>\n",
       "      <td>2019-06-05</td>\n",
       "      <td>22</td>\n",
       "      <td>2019-06-05 FR 8545</td>\n",
       "      <td>SXF-STN</td>\n",
       "      <td>50.99</td>\n",
       "      <td>50.99</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2019-06-03T23:00:00Z</td>\n",
       "      <td>2019-06-06</td>\n",
       "      <td>6</td>\n",
       "      <td>2019-06-06 FR 144</td>\n",
       "      <td>SXF-STN</td>\n",
       "      <td>73.43</td>\n",
       "      <td>61.19</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2019-06-04T11:00:00Z</td>\n",
       "      <td>2019-06-06</td>\n",
       "      <td>6</td>\n",
       "      <td>2019-06-06 FR 144</td>\n",
       "      <td>SXF-STN</td>\n",
       "      <td>73.43</td>\n",
       "      <td>61.19</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2019-06-04T23:00:00Z</td>\n",
       "      <td>2019-06-06</td>\n",
       "      <td>6</td>\n",
       "      <td>2019-06-06 FR 144</td>\n",
       "      <td>SXF-STN</td>\n",
       "      <td>61.19</td>\n",
       "      <td>61.19</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2019-06-05T11:00:00Z</td>\n",
       "      <td>2019-06-06</td>\n",
       "      <td>6</td>\n",
       "      <td>2019-06-06 FR 144</td>\n",
       "      <td>SXF-STN</td>\n",
       "      <td>61.19</td>\n",
       "      <td>61.19</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2019-06-03T11:00:00Z</td>\n",
       "      <td>2019-06-06</td>\n",
       "      <td>6</td>\n",
       "      <td>2019-06-06 FR 8542</td>\n",
       "      <td>STN-SXF</td>\n",
       "      <td>171.49</td>\n",
       "      <td>171.26</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2019-06-03T23:00:00Z</td>\n",
       "      <td>2019-06-06</td>\n",
       "      <td>6</td>\n",
       "      <td>2019-06-06 FR 8542</td>\n",
       "      <td>STN-SXF</td>\n",
       "      <td>171.49</td>\n",
       "      <td>171.26</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2019-06-04T11:00:00Z</td>\n",
       "      <td>2019-06-06</td>\n",
       "      <td>6</td>\n",
       "      <td>2019-06-06 FR 8542</td>\n",
       "      <td>STN-SXF</td>\n",
       "      <td>171.26</td>\n",
       "      <td>251.72</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2019-06-04T23:00:00Z</td>\n",
       "      <td>2019-06-06</td>\n",
       "      <td>6</td>\n",
       "      <td>2019-06-06 FR 8542</td>\n",
       "      <td>STN-SXF</td>\n",
       "      <td>251.72</td>\n",
       "      <td>252.02</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Request_Date Flight_Date  Departure_hour    flight_unique_id  \\\n",
       "index                                                                         \n",
       "1      2019-06-03T11:00:00Z  2019-06-05              19   2019-06-05 FR 146   \n",
       "2      2019-06-03T23:00:00Z  2019-06-05              19   2019-06-05 FR 146   \n",
       "3      2019-06-04T11:00:00Z  2019-06-05              19   2019-06-05 FR 146   \n",
       "4      2019-06-04T23:00:00Z  2019-06-05              19   2019-06-05 FR 146   \n",
       "5      2019-06-03T11:00:00Z  2019-06-05              21   2019-06-05 FR 147   \n",
       "6      2019-06-03T23:00:00Z  2019-06-05              21   2019-06-05 FR 147   \n",
       "7      2019-06-04T11:00:00Z  2019-06-05              21   2019-06-05 FR 147   \n",
       "8      2019-06-04T23:00:00Z  2019-06-05              21   2019-06-05 FR 147   \n",
       "9      2019-06-03T11:00:00Z  2019-06-05              22  2019-06-05 FR 8545   \n",
       "10     2019-06-03T23:00:00Z  2019-06-05              22  2019-06-05 FR 8545   \n",
       "11     2019-06-04T11:00:00Z  2019-06-05              22  2019-06-05 FR 8545   \n",
       "12     2019-06-04T23:00:00Z  2019-06-05              22  2019-06-05 FR 8545   \n",
       "13     2019-06-03T23:00:00Z  2019-06-06               6   2019-06-06 FR 144   \n",
       "14     2019-06-04T11:00:00Z  2019-06-06               6   2019-06-06 FR 144   \n",
       "15     2019-06-04T23:00:00Z  2019-06-06               6   2019-06-06 FR 144   \n",
       "16     2019-06-05T11:00:00Z  2019-06-06               6   2019-06-06 FR 144   \n",
       "17     2019-06-03T11:00:00Z  2019-06-06               6  2019-06-06 FR 8542   \n",
       "18     2019-06-03T23:00:00Z  2019-06-06               6  2019-06-06 FR 8542   \n",
       "19     2019-06-04T11:00:00Z  2019-06-06               6  2019-06-06 FR 8542   \n",
       "20     2019-06-04T23:00:00Z  2019-06-06               6  2019-06-06 FR 8542   \n",
       "\n",
       "      route_abb  Price_In_Eur  min_future_price_in_Eur  buy  \n",
       "index                                                        \n",
       "1       SXF-STN        208.07                   259.07    1  \n",
       "2       SXF-STN        259.07                   259.07    1  \n",
       "3       SXF-STN        259.07                   259.07    1  \n",
       "4       SXF-STN        259.07                   259.07    1  \n",
       "5       STN-SXF        143.86                   251.72    1  \n",
       "6       STN-SXF        252.06                   251.72    0  \n",
       "7       STN-SXF        251.72                   251.72    1  \n",
       "8       STN-SXF        251.72                   251.72    1  \n",
       "9       SXF-STN         22.17                    22.17    1  \n",
       "10      SXF-STN         22.17                    28.55    1  \n",
       "11      SXF-STN         28.55                    50.99    1  \n",
       "12      SXF-STN         50.99                    50.99    1  \n",
       "13      SXF-STN         73.43                    61.19    0  \n",
       "14      SXF-STN         73.43                    61.19    0  \n",
       "15      SXF-STN         61.19                    61.19    1  \n",
       "16      SXF-STN         61.19                    61.19    1  \n",
       "17      STN-SXF        171.49                   171.26    0  \n",
       "18      STN-SXF        171.49                   171.26    0  \n",
       "19      STN-SXF        171.26                   251.72    1  \n",
       "20      STN-SXF        251.72                   252.02    1  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_data(data):\n",
    "    # Datentypen Ã¤ndern\n",
    "    data['Flight_Date'] = pd.to_datetime(data['Flight_Date'])\n",
    "    data['Request_Date'] = pd.to_datetime(data['Request_Date'])\n",
    "    \n",
    "    # One Hot Encoding fÃ¼r Routen-Bezeichnungen\n",
    "    data = pd.get_dummies(data,prefix=['route'], columns = ['route_abb'], drop_first=False)\n",
    "    \n",
    "    # Flag, wenn die Anfrage die letzte Anfrage vor dem Flug ist\n",
    "    is_last_request = pd.DataFrame(data.groupby('flight_unique_id')['Request_Date'].max()).reset_index()\n",
    "    is_last_request['is_last_request'] = 1\n",
    "\n",
    "    data = data.merge(is_last_request, \n",
    "                      left_on=['flight_unique_id', 'Request_Date'], \n",
    "                      right_on=['flight_unique_id', 'Request_Date'], \n",
    "                      how='left')\n",
    "    data['is_last_request'] = data['is_last_request'].fillna(0)\n",
    "    data['is_last_request'] = data['is_last_request'].astype(int)\n",
    "    \n",
    "    # Anzahl der bisherigen Requests als Feature hinzufÃ¼gen\n",
    "    data = data.sort_values(['flight_unique_id', 'Request_Date'])\n",
    "    unique_flights = data['flight_unique_id'].unique()\n",
    "\n",
    "    requests_counter = 0\n",
    "    flight_id_index = 0\n",
    "    current_flight = unique_flights[flight_id_index]\n",
    "    number_of_requests_per_row = []\n",
    "\n",
    "    for index, row in  data.iterrows():\n",
    "        if row['flight_unique_id'] != current_flight:       \n",
    "            flight_id_index += 1\n",
    "            current_flight = unique_flights[flight_id_index]\n",
    "            requests_counter = 0\n",
    "        number_of_requests_per_row.append(requests_counter)\n",
    "        requests_counter += 1\n",
    "\n",
    "    data['previous_requests'] = number_of_requests_per_row\n",
    "    \n",
    "    # Datumsfelder in einzelne Bestandteile zerlegen\n",
    "    data['flight_weekday'] = data['Flight_Date'].dt.weekday\n",
    "    data['flight_day'] = data['Flight_Date'].dt.day\n",
    "    data['flight_month'] = data['Flight_Date'].dt.month \n",
    "    data['flight_is_weekend'] = data['flight_weekday'] >= 5\n",
    "\n",
    "    data['request_weekday'] = data['Request_Date'].dt.weekday\n",
    "    data['request_day'] = data['Request_Date'].dt.day\n",
    "    data['request_month'] = data['Request_Date'].dt.month\n",
    "    data['request_is_weekend'] = data['request_weekday'] >= 5\n",
    "    \n",
    "    data['request_hour'] = data['Request_Date'].dt.hour\n",
    "    \n",
    "    # Cyclische Features in Sinus und Cosinus ReprÃ¤sentation umwandeln\n",
    "    # Quelle: https://www.mikulskibartosz.name/time-in-machine-learning/\n",
    "    def encode(data, col, max_val):\n",
    "        data[col + '_sin'] = np.sin(2 * np.pi * data[col]/max_val)\n",
    "        data[col + '_cos'] = np.cos(2 * np.pi * data[col]/max_val)\n",
    "        return data\n",
    "\n",
    "    data = encode(data, 'request_weekday', 7)\n",
    "    data = encode(data, 'request_month', 12)\n",
    "    data = encode(data, 'request_day', 365)\n",
    "    data = encode(data, 'request_hour', 24)\n",
    "\n",
    "    data = encode(data, 'flight_weekday', 7)\n",
    "    data = encode(data, 'flight_month', 12)\n",
    "    data = encode(data, 'flight_day', 365)\n",
    "    data = encode(data, 'Departure_hour', 24)\n",
    "    \n",
    "    # Tage bis zum Flug berechnen\n",
    "    data['Request_Date_w/o_Time'] = pd.to_datetime(data['Request_Date']).dt.date\n",
    "    data['days_remaining'] = (pd.to_datetime(data['Flight_Date']).dt.date - data['Request_Date_w/o_Time']).dt.days\n",
    "    data.drop(['Request_Date_w/o_Time'],1, inplace=True)\n",
    "    \n",
    "    # Relevante Feiertage im Zeitraum der Daten, die in Berlin und oder Frankfurt gelten\n",
    "    # sowie Public Holidays in GroÃŸbritannien. \n",
    "    feiertage = {\n",
    "        '2019-06-09':'Pfingstsonntag',\n",
    "        '2019-06-10':'Pfingstmontag',\n",
    "        '2019-06-20':'Fronleichnam',\n",
    "        '2019-06-20':'Schulferien Beginn',\n",
    "        '2019-08-02':'Schulferien Ende',\n",
    "        '2019-08-26':'Summer Bank Holidays',\n",
    "        '2019-07-15':'School Summer Holidays Beginn',\n",
    "        '2019-09-06':'School Summer Holidays End'}\n",
    "\n",
    "    feiertage_df = pd.DataFrame(feiertage.items(), columns=['Datum_Feiertag', 'Feiertag_Bezeichnung'])\n",
    "    feiertage_df['Datum_Feiertag'] = pd.to_datetime(feiertage_df['Datum_Feiertag'])\n",
    "    \n",
    "    from datetime import datetime\n",
    "\n",
    "    day_diff_list = []\n",
    "    for index, row in feiertage_df.iterrows():\n",
    "        day_diff_list.append(abs((data['Flight_Date'] - row['Datum_Feiertag']).dt.days))\n",
    "        \n",
    "    feiertage_diff_df = pd.concat(day_diff_list, axis=1)\n",
    "    feiertage_diff_df = feiertage_diff_df.min(axis=1)\n",
    "    feiertage_diff_df = feiertage_diff_df.reset_index().drop('index', 1)\n",
    "    feiertage_diff_df.columns = ['Days_Untill_Event']\n",
    "\n",
    "    data = pd.concat([data, feiertage_diff_df], axis=1)\n",
    "\n",
    "    # Features skalieren\n",
    "    scaler = MinMaxScaler()\n",
    "    columns_to_be_scaled = ['Price_In_Eur', \n",
    "                         'min_future_price_in_Eur', \n",
    "                         'days_remaining', \n",
    "                         'previous_requests', \n",
    "                         'Days_Untill_Event']\n",
    "    to_be_scaled = data[columns_to_be_scaled]\n",
    "    scaled = pd.DataFrame(scaler.fit_transform(to_be_scaled), columns=columns_to_be_scaled)\n",
    "    data = pd.concat([data.reset_index(), scaled.reset_index()], axis=1)\n",
    "    \n",
    "    # Nicht mehr benÃ¶tigte Spalten entfernen\n",
    "    data.drop(['Request_Date', \n",
    "               'Flight_Date', \n",
    "               'Price_In_Eur', \n",
    "               'min_future_price_in_Eur', \n",
    "               'index', \n",
    "               'Departure_hour', \n",
    "               'flight_weekday', \n",
    "               'flight_day', \n",
    "               'flight_month', \n",
    "               'request_weekday', \n",
    "               'request_day', \n",
    "               'request_month', \n",
    "               'days_remaining',\n",
    "               'request_hour', \n",
    "               'Days_Untill_Event',\n",
    "               'previous_requests',\n",
    "               'flight_unique_id'], inplace=True, axis=1)\n",
    "    \n",
    "    # Boolean in Int umwandeln\n",
    "    data['request_is_weekend'] = data['request_is_weekend'].astype(int)\n",
    "    data['flight_is_weekend'] = data['flight_is_weekend'].astype(int)\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t2/86whqkvn0sb99n4gbl4pmjvm0000gn/T/ipykernel_11403/2324288434.py:72: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n",
      "  data.drop(['Request_Date_w/o_Time'],1, inplace=True)\n",
      "/var/folders/t2/86whqkvn0sb99n4gbl4pmjvm0000gn/T/ipykernel_11403/2324288434.py:97: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n",
      "  feiertage_diff_df = feiertage_diff_df.reset_index().drop('index', 1)\n"
     ]
    }
   ],
   "source": [
    "data = prep_data(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>buy</th>\n",
       "      <th>route_FRA-STN</th>\n",
       "      <th>route_STN-FRA</th>\n",
       "      <th>route_STN-SXF</th>\n",
       "      <th>route_SXF-STN</th>\n",
       "      <th>is_last_request</th>\n",
       "      <th>flight_is_weekend</th>\n",
       "      <th>request_is_weekend</th>\n",
       "      <th>request_weekday_sin</th>\n",
       "      <th>request_weekday_cos</th>\n",
       "      <th>...</th>\n",
       "      <th>request_hour_sin</th>\n",
       "      <th>request_hour_cos</th>\n",
       "      <th>flight_weekday_sin</th>\n",
       "      <th>flight_weekday_cos</th>\n",
       "      <th>flight_month_sin</th>\n",
       "      <th>flight_month_cos</th>\n",
       "      <th>flight_day_sin</th>\n",
       "      <th>flight_day_cos</th>\n",
       "      <th>Departure_hour_sin</th>\n",
       "      <th>Departure_hour_cos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.258819</td>\n",
       "      <td>-0.965926</td>\n",
       "      <td>0.974928</td>\n",
       "      <td>-0.222521</td>\n",
       "      <td>1.224647e-16</td>\n",
       "      <td>-1.000000e+00</td>\n",
       "      <td>0.085965</td>\n",
       "      <td>0.996298</td>\n",
       "      <td>-0.965926</td>\n",
       "      <td>0.258819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.258819</td>\n",
       "      <td>0.965926</td>\n",
       "      <td>0.974928</td>\n",
       "      <td>-0.222521</td>\n",
       "      <td>1.224647e-16</td>\n",
       "      <td>-1.000000e+00</td>\n",
       "      <td>0.085965</td>\n",
       "      <td>0.996298</td>\n",
       "      <td>-0.965926</td>\n",
       "      <td>0.258819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.781831</td>\n",
       "      <td>0.623490</td>\n",
       "      <td>...</td>\n",
       "      <td>0.258819</td>\n",
       "      <td>-0.965926</td>\n",
       "      <td>0.974928</td>\n",
       "      <td>-0.222521</td>\n",
       "      <td>1.224647e-16</td>\n",
       "      <td>-1.000000e+00</td>\n",
       "      <td>0.085965</td>\n",
       "      <td>0.996298</td>\n",
       "      <td>-0.965926</td>\n",
       "      <td>0.258819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.781831</td>\n",
       "      <td>0.623490</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.258819</td>\n",
       "      <td>0.965926</td>\n",
       "      <td>0.974928</td>\n",
       "      <td>-0.222521</td>\n",
       "      <td>1.224647e-16</td>\n",
       "      <td>-1.000000e+00</td>\n",
       "      <td>0.085965</td>\n",
       "      <td>0.996298</td>\n",
       "      <td>-0.965926</td>\n",
       "      <td>0.258819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.258819</td>\n",
       "      <td>-0.965926</td>\n",
       "      <td>0.974928</td>\n",
       "      <td>-0.222521</td>\n",
       "      <td>1.224647e-16</td>\n",
       "      <td>-1.000000e+00</td>\n",
       "      <td>0.085965</td>\n",
       "      <td>0.996298</td>\n",
       "      <td>-0.707107</td>\n",
       "      <td>0.707107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83619</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.433884</td>\n",
       "      <td>-0.900969</td>\n",
       "      <td>...</td>\n",
       "      <td>0.258819</td>\n",
       "      <td>-0.965926</td>\n",
       "      <td>0.781831</td>\n",
       "      <td>0.623490</td>\n",
       "      <td>-1.000000e+00</td>\n",
       "      <td>-1.836970e-16</td>\n",
       "      <td>0.171293</td>\n",
       "      <td>0.985220</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>-0.866025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83620</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.433884</td>\n",
       "      <td>-0.900969</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.258819</td>\n",
       "      <td>0.965926</td>\n",
       "      <td>0.781831</td>\n",
       "      <td>0.623490</td>\n",
       "      <td>-1.000000e+00</td>\n",
       "      <td>-1.836970e-16</td>\n",
       "      <td>0.171293</td>\n",
       "      <td>0.985220</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>-0.866025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83621</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.433884</td>\n",
       "      <td>-0.900969</td>\n",
       "      <td>...</td>\n",
       "      <td>0.258819</td>\n",
       "      <td>-0.965926</td>\n",
       "      <td>0.781831</td>\n",
       "      <td>0.623490</td>\n",
       "      <td>-1.000000e+00</td>\n",
       "      <td>-1.836970e-16</td>\n",
       "      <td>0.171293</td>\n",
       "      <td>0.985220</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>-0.866025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83622</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.433884</td>\n",
       "      <td>-0.900969</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.258819</td>\n",
       "      <td>0.965926</td>\n",
       "      <td>0.781831</td>\n",
       "      <td>0.623490</td>\n",
       "      <td>-1.000000e+00</td>\n",
       "      <td>-1.836970e-16</td>\n",
       "      <td>0.171293</td>\n",
       "      <td>0.985220</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>-0.866025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83623</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.974928</td>\n",
       "      <td>-0.222521</td>\n",
       "      <td>...</td>\n",
       "      <td>0.258819</td>\n",
       "      <td>-0.965926</td>\n",
       "      <td>0.781831</td>\n",
       "      <td>0.623490</td>\n",
       "      <td>-1.000000e+00</td>\n",
       "      <td>-1.836970e-16</td>\n",
       "      <td>0.171293</td>\n",
       "      <td>0.985220</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>-0.866025</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>83624 rows Ã— 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       buy  route_FRA-STN  route_STN-FRA  route_STN-SXF  route_SXF-STN  \\\n",
       "0        1              0              0              0              1   \n",
       "1        1              0              0              0              1   \n",
       "2        1              0              0              0              1   \n",
       "3        1              0              0              0              1   \n",
       "4        1              0              0              1              0   \n",
       "...    ...            ...            ...            ...            ...   \n",
       "83619    1              0              0              0              1   \n",
       "83620    0              0              0              0              1   \n",
       "83621    0              0              0              0              1   \n",
       "83622    1              0              0              0              1   \n",
       "83623    1              0              0              0              1   \n",
       "\n",
       "       is_last_request  flight_is_weekend  request_is_weekend  \\\n",
       "0                    0                  0                   0   \n",
       "1                    0                  0                   0   \n",
       "2                    0                  0                   0   \n",
       "3                    1                  0                   0   \n",
       "4                    0                  0                   0   \n",
       "...                ...                ...                 ...   \n",
       "83619                0                  0                   0   \n",
       "83620                0                  0                   0   \n",
       "83621                0                  0                   0   \n",
       "83622                0                  0                   0   \n",
       "83623                1                  0                   1   \n",
       "\n",
       "       request_weekday_sin  request_weekday_cos  ...  request_hour_sin  \\\n",
       "0                 0.000000             1.000000  ...          0.258819   \n",
       "1                 0.000000             1.000000  ...         -0.258819   \n",
       "2                 0.781831             0.623490  ...          0.258819   \n",
       "3                 0.781831             0.623490  ...         -0.258819   \n",
       "4                 0.000000             1.000000  ...          0.258819   \n",
       "...                    ...                  ...  ...               ...   \n",
       "83619             0.433884            -0.900969  ...          0.258819   \n",
       "83620             0.433884            -0.900969  ...         -0.258819   \n",
       "83621            -0.433884            -0.900969  ...          0.258819   \n",
       "83622            -0.433884            -0.900969  ...         -0.258819   \n",
       "83623            -0.974928            -0.222521  ...          0.258819   \n",
       "\n",
       "       request_hour_cos  flight_weekday_sin  flight_weekday_cos  \\\n",
       "0             -0.965926            0.974928           -0.222521   \n",
       "1              0.965926            0.974928           -0.222521   \n",
       "2             -0.965926            0.974928           -0.222521   \n",
       "3              0.965926            0.974928           -0.222521   \n",
       "4             -0.965926            0.974928           -0.222521   \n",
       "...                 ...                 ...                 ...   \n",
       "83619         -0.965926            0.781831            0.623490   \n",
       "83620          0.965926            0.781831            0.623490   \n",
       "83621         -0.965926            0.781831            0.623490   \n",
       "83622          0.965926            0.781831            0.623490   \n",
       "83623         -0.965926            0.781831            0.623490   \n",
       "\n",
       "       flight_month_sin  flight_month_cos  flight_day_sin  flight_day_cos  \\\n",
       "0          1.224647e-16     -1.000000e+00        0.085965        0.996298   \n",
       "1          1.224647e-16     -1.000000e+00        0.085965        0.996298   \n",
       "2          1.224647e-16     -1.000000e+00        0.085965        0.996298   \n",
       "3          1.224647e-16     -1.000000e+00        0.085965        0.996298   \n",
       "4          1.224647e-16     -1.000000e+00        0.085965        0.996298   \n",
       "...                 ...               ...             ...             ...   \n",
       "83619     -1.000000e+00     -1.836970e-16        0.171293        0.985220   \n",
       "83620     -1.000000e+00     -1.836970e-16        0.171293        0.985220   \n",
       "83621     -1.000000e+00     -1.836970e-16        0.171293        0.985220   \n",
       "83622     -1.000000e+00     -1.836970e-16        0.171293        0.985220   \n",
       "83623     -1.000000e+00     -1.836970e-16        0.171293        0.985220   \n",
       "\n",
       "       Departure_hour_sin  Departure_hour_cos  \n",
       "0               -0.965926            0.258819  \n",
       "1               -0.965926            0.258819  \n",
       "2               -0.965926            0.258819  \n",
       "3               -0.965926            0.258819  \n",
       "4               -0.707107            0.707107  \n",
       "...                   ...                 ...  \n",
       "83619            0.500000           -0.866025  \n",
       "83620            0.500000           -0.866025  \n",
       "83621            0.500000           -0.866025  \n",
       "83622            0.500000           -0.866025  \n",
       "83623            0.500000           -0.866025  \n",
       "\n",
       "[83624 rows x 24 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t2/86whqkvn0sb99n4gbl4pmjvm0000gn/T/ipykernel_11403/3488605291.py:3: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n",
      "  X = data.drop(['buy'], 1)\n"
     ]
    }
   ],
   "source": [
    "# Daten in Trainings- und Testdaten aufteilen\n",
    "y = data['buy']\n",
    "X = data.drop(['buy'], 1)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=99, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import sample\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import tree\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, x_train, y_train, x_test, y_test):\n",
    "    model = model.fit(x_train, y_train)\n",
    "    print('Training Score:', model.score(x_train, y_train))\n",
    "    \n",
    "    # Predictions on the test dataset\n",
    "    predicted = pd.DataFrame(model.predict(x_test))\n",
    "    # Probabilities on the test dataset\n",
    "    probs = pd.DataFrame(model.predict_proba(x_test))\n",
    "    print('Test Score:', metrics.accuracy_score(y_test, predicted))\n",
    "    \n",
    "    print(metrics.classification_report(y_test, predicted))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "list_of_models = [RandomForestClassifier(), \n",
    "                  #SVC(), \n",
    "                  tree.DecisionTreeClassifier(max_depth=10), \n",
    "                  LogisticRegression(), \n",
    "                  KNeighborsClassifier(n_neighbors=5), \n",
    "                  GaussianNB()]\n",
    "\n",
    "for model in list_of_models:\n",
    "    evaluate_model(model, x_train, y_train, x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "scores = cross_val_score(RandomForestClassifier(), x_train, y_train,\n",
    " scoring=\"neg_mean_squared_error\", cv=10)\n",
    "\n",
    "tree_rmse_scores = np.sqrt(-scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_scores(scores):\n",
    "    print(\"Scores:\", scores)\n",
    "    print(\"Mean:\", scores.mean())\n",
    "    print(\"Standard deviation:\", scores.std())\n",
    "\n",
    "display_scores(tree_rmse_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from numpy import mean\n",
    "from numpy import std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = KFold(n_splits=10, random_state=1, shuffle=True)\n",
    "\n",
    "model = RandomForestClassifier()\n",
    "\n",
    "scores = cross_val_score(model, x_train, y_train, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "\n",
    "print('Accuracy: %.3f (%.3f)' % (mean(scores), std(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt']\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "max_depth.append(None)\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 5, 10]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True, False]\n",
    "\n",
    "# Create the random grid\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}\n",
    "\n",
    "rf = RandomForestClassifier()\n",
    "\n",
    "# rf_random = RandomizedSearchCV(estimator = rf, \n",
    "#                                param_distributions = random_grid, \n",
    "#                                n_iter = 100, \n",
    "#                                cv = 3, \n",
    "#                                verbose=2, \n",
    "#                                random_state=42, \n",
    "#                                n_jobs = -1)\n",
    "\n",
    "# rf_random.fit(x_train, y_train)\n",
    "# rf_random.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_grid = {'n_estimators': [10, 30, 100, 200],\n",
    "               'max_features': ['auto', 'sqrt']}\n",
    "#                'max_depth': max_depth,\n",
    "#                'min_samples_split': min_samples_split,\n",
    "#                'min_samples_leaf': min_samples_leaf,\n",
    "#                'bootstrap': bootstrap}\n",
    "\n",
    "rf = RandomForestClassifier()\n",
    "\n",
    "rf_random = RandomizedSearchCV(estimator = rf, \n",
    "                               param_distributions = random_grid, \n",
    "                               n_iter = 100, \n",
    "                               cv = 5, \n",
    "                               verbose=2, \n",
    "                               random_state=42, \n",
    "                               n_jobs = -1)\n",
    "\n",
    "rf_random.fit(x_train, y_train)\n",
    "rf_random.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cv = KFold(n_splits=10, random_state=1, shuffle=True)\n",
    "\n",
    "model = RandomForestClassifier(n_estimators= 200, \n",
    "                               max_features= 'sqrt')\n",
    "\n",
    "scores = cross_val_score(model, x_train.drop(['request_is_weekend', \n",
    "                                              'request_month_sin', \n",
    "                                              'request_month_cos'],1), y_train, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "\n",
    "model = model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Accuracy: %.3f (%.3f)' % (mean(scores), std(scores)))\n",
    "\n",
    "# Predictions on the test dataset\n",
    "predicted = pd.DataFrame(model.predict(x_test))\n",
    "# Probabilities on the test dataset\n",
    "probs = pd.DataFrame(model.predict_proba(x_test))\n",
    "print('Test Score:', metrics.accuracy_score(y_test, predicted))\n",
    "\n",
    "print(metrics.classification_report(y_test, predicted))\n",
    "print(model.feature_importances_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.pyplot import figure\n",
    "figure(figsize=(10, 10), dpi=80)\n",
    "\n",
    "sorted_idx = model.feature_importances_.argsort()\n",
    "plt.barh(x_train.columns[sorted_idx], model.feature_importances_[sorted_idx])\n",
    "plt.xlabel(\"Random Forest Feature Importance\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Durchschnittlich liegen zwischen dem Abfragedatum und dem Flug 38 Tage. Der grÃ¶ÃŸte Abstand betrÃ¤gt 99 Tage und der geringste einen Tag. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eff1338a",
   "metadata": {},
   "source": [
    "## 3. Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "48e25d9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from keras.layers import Dense\n",
    "from keras.models import Sequential\n",
    "from keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "a254396e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "1830/1830 [==============================] - 8s 4ms/step - loss: nan - accuracy: 0.7490 - val_loss: nan - val_accuracy: 0.8319\n",
      "Epoch 2/15\n",
      "1830/1830 [==============================] - 11s 6ms/step - loss: nan - accuracy: 0.7523 - val_loss: nan - val_accuracy: 0.8319\n",
      "Epoch 3/15\n",
      "1830/1830 [==============================] - 6s 3ms/step - loss: nan - accuracy: 0.7523 - val_loss: nan - val_accuracy: 0.8319\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f92c10b62b0>"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_cols = x_train.shape[1]\n",
    "\n",
    "# Set up the model: model\n",
    "model = Sequential()\n",
    "\n",
    "# Add the first layer\n",
    "model.add(Dense(1000, activation='relu', input_shape=(n_cols,)))\n",
    "model.add(Dense(100, activation='relu'))\n",
    "model.add(Dense(100, activation='relu'))\n",
    "model.add(Dense(100, activation='relu'))\n",
    "model.add(Dense(1, activation='softmax'))\n",
    "\n",
    "opt = keras.optimizers.SGD(learning_rate=0.1)\n",
    "\n",
    "model.compile(\n",
    "    optimizer=opt, \n",
    "    loss='categorical_crossentropy', \n",
    "    metrics=['accuracy'])\n",
    "\n",
    "early_stopping_monitor = EarlyStopping(patience=3)\n",
    "\n",
    "model.fit(\n",
    "    X, \n",
    "    y, \n",
    "    validation_split=0.3, \n",
    "    epochs=15, \n",
    "    callbacks=[early_stopping_monitor])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b79fde5d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "cce9351d",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'History' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/t2/86whqkvn0sb99n4gbl4pmjvm0000gn/T/ipykernel_11403/3008598982.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Epochs'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Validation score'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'History' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(model.history['val_loss'], 'r')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Validation score')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "21283d9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "bcf91c00",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN, infinity or a value too large for dtype('float32').",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/t2/86whqkvn0sb99n4gbl4pmjvm0000gn/T/ipykernel_11403/3320428852.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassification_report\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/envs/DataMiningWS202122/lib/python3.9/site-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36mclassification_report\u001b[0;34m(y_true, y_pred, labels, target_names, sample_weight, digits, output_dict, zero_division)\u001b[0m\n\u001b[1;32m   2108\u001b[0m     \"\"\"\n\u001b[1;32m   2109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2110\u001b[0;31m     \u001b[0my_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2112\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/DataMiningWS202122/lib/python3.9/site-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     84\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m     \u001b[0mtype_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m     \u001b[0mtype_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m     \u001b[0my_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mtype_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype_pred\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/DataMiningWS202122/lib/python3.9/site-packages/sklearn/utils/multiclass.py\u001b[0m in \u001b[0;36mtype_of_target\u001b[0;34m(y)\u001b[0m\n\u001b[1;32m    322\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"f\"\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m         \u001b[0;31m# [.1, .2, 3] or [[.1, .2, 3]] or [[1., .2]] and not [1., 2., 3.]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 324\u001b[0;31m         \u001b[0m_assert_all_finite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    325\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m\"continuous\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msuffix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/DataMiningWS202122/lib/python3.9/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[0;34m(X, allow_nan, msg_dtype)\u001b[0m\n\u001b[1;32m    112\u001b[0m         ):\n\u001b[1;32m    113\u001b[0m             \u001b[0mtype_err\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"infinity\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mallow_nan\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"NaN, infinity\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m    115\u001b[0m                 msg_err.format(\n\u001b[1;32m    116\u001b[0m                     \u001b[0mtype_err\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg_dtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mmsg_dtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Input contains NaN, infinity or a value too large for dtype('float32')."
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(y_test, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FÃ¼r eine optimale Vorhersage wÃ¤ren natÃ¼rlich Informationen zur Anzahl tatsÃ¤chlich verfÃ¼gbarer SitzplÃ¤tze oder detailiertere Informationen zu verkauften Ticket-Typen (Business Class, Economy Class, GeschÃ¤ftsreisende, etc. - wenn auch vermutlich auf kÃ¼rzeren Strecken wie denen im Datensatz weniger relevant) hilfreich, die jedoch typischerweise nicht Ã¶ffentlich verfÃ¼gbar sind (vgl. Manolis Papadakis 2021: Predicting Airfare Prices, S. 1. http://cs229.stanford.edu/proj2012/Papadakis-PredictingAirfarePrices.pdf Letzter Zugriff: 06.12.2021)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.skew()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die Verteilung der Features (mit Ausnahme der Preisbasierten Spalten) zeigt mit Werten zwischen -0,5 und 0,5 keine Hinweise auf deutlich asymetrische Verteilungen (vgl. https://medium.com/@atanudan/kurtosis-skew-function-in-pandas-aa63d72e20de) . GrundsÃ¤tzlich besteht bei den vorhandenen Features keine Notwendigkeit zur Normalisierung. Nur kategorische Werte mÃ¼ssen fÃ¼r die Verwendung in den Modellen noch codiert werden."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ãœber die bestehenden Features hinaus werden folgende Features fÃ¼r die Vorhersage ergÃ¤nzt:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Wochentag\n",
    "- Tage bis zum Flug\n",
    "- Tage bis zum nÃ¤chsten Feiertag"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ob diese Features einen tatsÃ¤chlichen Mehrwert fÃ¼r die Vorhersage liefern, muss im zweiten Teil der Projektarbeit ermittelt werden."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
